---
title: Latest 15 Papers - July 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Visual Position Prompt for MLLM based Visual Grounding](http://arxiv.org/abs/2503.15426v4)** | 2025-07-16 |  |
| **[HueManity: Probing Fine-Grained Visual Perception in MLLMs](http://arxiv.org/abs/2506.03194v2)** | 2025-07-16 |  |
| **[Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](http://arxiv.org/abs/2507.11662v1)** | 2025-07-15 | <details><summary>Our c...</summary><p>Our code and data are publicly available at https://github.com/mshalimay/mllm-verifiers-abias-sgv</p></details> |
| **[DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs](http://arxiv.org/abs/2507.10302v1)** | 2025-07-14 | ICCV 2025 |
| **[A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images](http://arxiv.org/abs/2507.10202v1)** | 2025-07-14 | <details><summary>Accep...</summary><p>Accepted at CVPR 2025 Workshop on Emergent Visual Abilities and Limits of Foundation Models</p></details> |
| **[Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](http://arxiv.org/abs/2506.10521v4)** | 2025-07-14 | 82 pages |
| **[SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs](http://arxiv.org/abs/2507.07610v2)** | 2025-07-14 |  |
| **[LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents](http://arxiv.org/abs/2503.10200v3)** | 2025-07-14 | <details><summary>accep...</summary><p>accepted in ICCV 2025</p></details> |
| **[A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends](http://arxiv.org/abs/2507.09861v1)** | 2025-07-14 | Work in progress |
| **[InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling](http://arxiv.org/abs/2501.12386v3)** | 2025-07-13 | technical report |
| **[EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique](http://arxiv.org/abs/2507.09374v1)** | 2025-07-12 | 14 pages,4 figures |
| **[Visual Semantic Description Generation with MLLMs for Image-Text Matching](http://arxiv.org/abs/2507.08590v1)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted by ICME2025 oral</p></details> |
| **[Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency](http://arxiv.org/abs/2507.08309v1)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted by ACL 2025 Findings</p></details> |
| **[M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning](http://arxiv.org/abs/2507.08306v1)** | 2025-07-11 | 31pages, 14 figures |
| **[OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding](http://arxiv.org/abs/2507.07984v1)** | 2025-07-10 | <details><summary>28 pa...</summary><p>28 pages, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. Project Page: https://rbler1234.github.io/OSTBench.github.io/</p></details> |

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](http://arxiv.org/abs/2507.12440v1)** | 2025-07-16 | <details><summary>More ...</summary><p>More videos can be found on our website: https://rchalyang.github.io/EgoVLA</p></details> |
| **[Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models](http://arxiv.org/abs/2502.19417v2)** | 2025-07-15 | ICML 2025 |
| **[Vision Language Action Models in Robotic Manipulation: A Systematic Review](http://arxiv.org/abs/2507.10672v1)** | 2025-07-14 | <details><summary>submi...</summary><p>submitted to annual review in control</p></details> |
| **[Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization](http://arxiv.org/abs/2507.09160v1)** | 2025-07-12 |  |
| **[VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](http://arxiv.org/abs/2507.05116v2)** | 2025-07-10 |  |
| **[3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds](http://arxiv.org/abs/2507.06484v1)** | 2025-07-09 | <details><summary>proje...</summary><p>project website: https://ai.stanford.edu/~sunfanyun/3d-generalist/</p></details> |
| **[Hume: Introducing System-2 Thinking in Visual-Language-Action Model](http://arxiv.org/abs/2505.21432v4)** | 2025-07-08 |  |
| **[NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving](http://arxiv.org/abs/2507.05227v1)** | 2025-07-07 | <details><summary>Accep...</summary><p>Accepted by ACM Multimedia 2025</p></details> |
| **[RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models](http://arxiv.org/abs/2506.17811v2)** | 2025-07-07 |  |
| **[DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge](http://arxiv.org/abs/2507.04447v1)** | 2025-07-06 |  |
| **[Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties](http://arxiv.org/abs/2507.04227v1)** | 2025-07-06 |  |
| **[DexVLG: Dexterous Vision-Language-Grasp Model at Scale](http://arxiv.org/abs/2507.02747v1)** | 2025-07-03 |  |
| **[TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control](http://arxiv.org/abs/2507.01424v2)** | 2025-07-03 |  |
| **[cVLA: Towards Efficient Camera-Space VLAs](http://arxiv.org/abs/2507.02190v1)** | 2025-07-02 | 20 pages, 10 figures |
| **[A Survey on Vision-Language-Action Models: An Action Tokenization Perspective](http://arxiv.org/abs/2507.01925v1)** | 2025-07-02 | 70 pages, 5 figures |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **["Is it always watching? Is it always listening?" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots](http://arxiv.org/abs/2507.10786v2)** | 2025-07-16 |  |
| **[Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning](http://arxiv.org/abs/2507.12391v1)** | 2025-07-16 | <details><summary>Accep...</summary><p>Accepted at the 2025 SICE Festival with Annual Conference (SICE FES)</p></details> |
| **[Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming](http://arxiv.org/abs/2507.11498v2)** | 2025-07-16 |  |
| **[Robot Metabolism: Towards machines that can grow by consuming other machines](http://arxiv.org/abs/2411.11192v2)** | 2025-07-16 | <details><summary>Manus...</summary><p>Manuscript combined with Supplementary Materials File for arXiv submission</p></details> |
| **[Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](http://arxiv.org/abs/2507.12273v1)** | 2025-07-16 |  |
| **[MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping](http://arxiv.org/abs/2507.10158v2)** | 2025-07-16 | <details><summary>The w...</summary><p>The work is accepted for presentation at IEEE SMC 2025</p></details> |
| **[Leveraging Sidewalk Robots for Walkability-Related Analyses](http://arxiv.org/abs/2507.12148v1)** | 2025-07-16 |  |
| **[SPARK: A Modular Benchmark for Humanoid Robot Safety](http://arxiv.org/abs/2502.03132v2)** | 2025-07-16 | <details><summary>Prese...</summary><p>Presented at IFAC Symposium on Robotics</p></details> |
| **[Robust Route Planning for Sidewalk Delivery Robots](http://arxiv.org/abs/2507.12067v1)** | 2025-07-16 |  |
| **[A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications](http://arxiv.org/abs/2507.11880v1)** | 2025-07-16 | 37 pages, 33 figures |
| **[The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey](http://arxiv.org/abs/2507.11840v1)** | 2025-07-16 |  |
| **[Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision](http://arxiv.org/abs/2504.02477v2)** | 2025-07-16 | <details><summary>27 pa...</summary><p>27 pages, 11 figures, survey paper submitted to Information Fusion</p></details> |
| **[Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies](http://arxiv.org/abs/2507.11770v1)** | 2025-07-15 | <details><summary>8 pag...</summary><p>8 pages, 7 figures, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2025)</p></details> |
| **[A Roadmap for Climate-Relevant Robotics Research](http://arxiv.org/abs/2507.11623v1)** | 2025-07-15 |  |
| **[LLM-based ambiguity detection in natural language instructions for collaborative surgical robots](http://arxiv.org/abs/2507.11525v1)** | 2025-07-15 | <details><summary>Accep...</summary><p>Accepted at 2025 IEEE International Conference on Robot and Human Interactive Communication (ROMAN)</p></details> |

## diffusion policy
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](http://arxiv.org/abs/2507.11662v1)** | 2025-07-15 | <details><summary>Our c...</summary><p>Our code and data are publicly available at https://github.com/mshalimay/mllm-verifiers-abias-sgv</p></details> |
| **[AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air](http://arxiv.org/abs/2507.11515v1)** | 2025-07-15 | 11 pages, 8 figures |
| **[RA-DP: Rapid Adaptive Diffusion Policy for Training-Free High-frequency Robotics Replanning](http://arxiv.org/abs/2503.04051v2)** | 2025-07-15 | <details><summary>Accep...</summary><p>Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025</p></details> |
| **[Ark: An Open-source Python-based Framework for Robot Learning](http://arxiv.org/abs/2506.21628v2)** | 2025-07-14 |  |
| **[Spatial-Temporal Aware Visuomotor Diffusion Policy Learning](http://arxiv.org/abs/2507.06710v2)** | 2025-07-13 |  |
| **[Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees](http://arxiv.org/abs/2507.10602v1)** | 2025-07-12 | 73 pages |
| **[Distributional Soft Actor-Critic with Diffusion Policy](http://arxiv.org/abs/2507.01381v3)** | 2025-07-11 | <details><summary>Accep...</summary><p>Accepted IEEE ITSC 2025</p></details> |
| **[GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving](http://arxiv.org/abs/2503.05689v4)** | 2025-07-10 |  |
| **[Latent Action Diffusion for Cross-Embodiment Manipulation](http://arxiv.org/abs/2506.14608v2)** | 2025-07-09 | 15 pages, 7 figures |
| **[Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps](http://arxiv.org/abs/2505.10482v3)** | 2025-07-08 | <details><summary>9 pag...</summary><p>9 pages for main text, 23 pages in total, submitted to Neurips, 13 figures</p></details> |
| **[Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning](http://arxiv.org/abs/2507.05695v1)** | 2025-07-08 |  |
| **[A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation](http://arxiv.org/abs/2507.05331v1)** | 2025-07-07 |  |
| **[VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation](http://arxiv.org/abs/2507.04524v1)** | 2025-07-06 |  |
| **[SE(3)-Equivariant Diffusion Policy in Spherical Fourier Space](http://arxiv.org/abs/2507.01723v1)** | 2025-07-02 | <details><summary>Accep...</summary><p>Accepted at ICML 2025</p></details> |
| **[DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover](http://arxiv.org/abs/2506.23152v3)** | 2025-07-02 | <details><summary>Comme...</summary><p>Comments: Accepted by ICCV 2025. Project page: https://dexh2r.github.io/</p></details> |

