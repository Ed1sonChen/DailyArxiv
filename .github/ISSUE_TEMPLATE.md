---
title: Latest 15 Papers - September 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models](http://arxiv.org/abs/2509.07962v1)** | 2025-09-09 | <details><summary>Accep...</summary><p>Accepted to CoRL 2025, project page: \url{https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/}</p></details> |
| **[Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](http://arxiv.org/abs/2509.07957v1)** | 2025-09-09 | <details><summary>This ...</summary><p>This paper is submitted to IEEE IROS 2025 Workshop AIR4S</p></details> |
| **[EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](http://arxiv.org/abs/2508.21112v3)** | 2025-09-09 |  |
| **[F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](http://arxiv.org/abs/2509.06951v2)** | 2025-09-09 | <details><summary>Homep...</summary><p>Homepage: https://aopolin-lv.github.io/F1-VLA/</p></details> |
| **[LLaDA-VLA: Vision Language Diffusion Action Models](http://arxiv.org/abs/2509.06932v1)** | 2025-09-08 |  |
| **[CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](http://arxiv.org/abs/2509.06819v1)** | 2025-09-08 | 5 pages, 5 figures |
| **[Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy](http://arxiv.org/abs/2503.19757v2)** | 2025-09-06 | <details><summary>Prepr...</summary><p>Preprint; https://robodita.github.io; To appear in ICCV2025</p></details> |
| **[4D Visual Pre-training for Robot Learning](http://arxiv.org/abs/2508.17230v2)** | 2025-09-06 |  |
| **[SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning](http://arxiv.org/abs/2509.05614v1)** | 2025-09-06 | 8pages, 10 figures, |
| **[OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](http://arxiv.org/abs/2509.05578v1)** | 2025-09-06 |  |
| **[OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation](http://arxiv.org/abs/2509.05513v1)** | 2025-09-05 | 4 pages, 1 figure |
| **[FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](http://arxiv.org/abs/2509.04996v1)** | 2025-09-05 | <details><summary>Publi...</summary><p>Published at CoRL 2025</p></details> |
| **[Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](http://arxiv.org/abs/2509.02055v2)** | 2025-09-05 | <details><summary>The f...</summary><p>The first three authors contributed equally</p></details> |
| **[Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](http://arxiv.org/abs/2509.04063v1)** | 2025-09-04 |  |
| **[FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](http://arxiv.org/abs/2509.04018v1)** | 2025-09-04 |  |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](http://arxiv.org/abs/2509.07957v1)** | 2025-09-09 | <details><summary>This ...</summary><p>This paper is submitted to IEEE IROS 2025 Workshop AIR4S</p></details> |
| **[RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction](http://arxiv.org/abs/2509.07953v1)** | 2025-09-09 |  |
| **[Knowledge Isn't Power: The Ethics of Social Robots and the Difficulty of Informed Consent](http://arxiv.org/abs/2509.07942v1)** | 2025-09-09 | <details><summary>Submi...</summary><p>Submitted to the International Journal of Social Robotics. 18 pages, 1 figure</p></details> |
| **[Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability](http://arxiv.org/abs/2509.07916v1)** | 2025-09-09 |  |
| **[A Robot That Listens: Enhancing Self-Disclosure and Engagement Through Sentiment-based Backchannels and Active Listening](http://arxiv.org/abs/2509.07873v1)** | 2025-09-09 |  |
| **[Monte Carlo Tree Search with Tensor Factorization for Robot Optimization](http://arxiv.org/abs/2507.04949v2)** | 2025-09-09 | 21 pages, 11 figures |
| **[EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](http://arxiv.org/abs/2508.21112v3)** | 2025-09-09 |  |
| **[MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](http://arxiv.org/abs/2507.18206v2)** | 2025-09-09 | 9 pages, 5 figures |
| **[TrojanRobot: Physical-world Backdoor Attacks Against VLM-based Robotic Manipulation](http://arxiv.org/abs/2411.11683v4)** | 2025-09-09 |  |
| **[Collaborative Exploration with a Marsupial Ground-Aerial Robot Team through Task-Driven Map Compression](http://arxiv.org/abs/2509.07655v1)** | 2025-09-09 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Robotics and Automation Letters (RA-L)</p></details> |
| **[Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network](http://arxiv.org/abs/2509.07646v1)** | 2025-09-09 |  |
| **[Bio-inspired decision making in swarms under biases from stubborn robots, corrupted communication, and independent discovery](http://arxiv.org/abs/2509.07561v1)** | 2025-09-09 |  |
| **[SAMba-UNet: SAM2-Mamba UNet for Cardiac MRI in Medical Robotic Perception](http://arxiv.org/abs/2505.16304v2)** | 2025-09-09 |  |
| **[Frequency Domain Enhanced U-Net for Low-Frequency Information-Rich Image Segmentation in Surgical and Deep-Sea Exploration Robots](http://arxiv.org/abs/2502.03829v3)** | 2025-09-09 |  |
| **[Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction](http://arxiv.org/abs/2509.07496v1)** | 2025-09-09 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images](http://arxiv.org/abs/2509.07966v1)** | 2025-09-09 | Work in Progress |
| **[MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning](http://arxiv.org/abs/2408.11505v3)** | 2025-09-09 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE TMI for possible publication</p></details> |
| **[Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease](http://arxiv.org/abs/2509.07613v1)** | 2025-09-09 |  |
| **[Visuospatial Cognitive Assistant](http://arxiv.org/abs/2505.12312v4)** | 2025-09-09 | <details><summary>31 pa...</summary><p>31 pages, 10 figures, 6 tables</p></details> |
| **[InteractPro: A Unified Framework for Motion-Aware Image Composition](http://arxiv.org/abs/2409.10090v3)** | 2025-09-09 |  |
| **[Fine-Tuning Vision-Language Models for Visual Navigation Assistance](http://arxiv.org/abs/2509.07488v1)** | 2025-09-09 |  |
| **[DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis](http://arxiv.org/abs/2509.07463v1)** | 2025-09-09 |  |
| **["Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection](http://arxiv.org/abs/2508.20670v2)** | 2025-09-09 |  |
| **[Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision](http://arxiv.org/abs/2509.00700v2)** | 2025-09-09 | <details><summary>Link ...</summary><p>Link to publicly available codes is added</p></details> |
| **[SpecifyUI: Supporting Iterative UI Design Intent Expression through Structured Specifications and Generative AI](http://arxiv.org/abs/2509.07334v1)** | 2025-09-09 | 27 pages, 12 figures |
| **[RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events](http://arxiv.org/abs/2509.01907v2)** | 2025-09-09 | under review |
| **[Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges](http://arxiv.org/abs/2507.02074v2)** | 2025-09-08 |  |
| **[Grounding DINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](http://arxiv.org/abs/2506.23903v3)** | 2025-09-08 | <details><summary>11 pa...</summary><p>11 pages, 3 figures, 7 tables</p></details> |
| **[Understanding Museum Exhibits using Vision-Language Reasoning](http://arxiv.org/abs/2412.01370v2)** | 2025-09-08 | <details><summary>Accep...</summary><p>Accepted at ICCV 2025</p></details> |
| **[LLaDA-VLA: Vision Language Diffusion Action Models](http://arxiv.org/abs/2509.06932v1)** | 2025-09-08 |  |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning](http://arxiv.org/abs/2509.07945v1)** | 2025-09-09 | 43 pages, 19 figures |
| **[LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences](http://arxiv.org/abs/2508.03692v2)** | 2025-09-09 | <details><summary>Prepr...</summary><p>Preprint; 28 pages, 18 figures, 12 tables; Project Page at https://lidarcrafter.github.io</p></details> |
| **[When Do Neural Networks Learn World Models?](http://arxiv.org/abs/2502.09297v5)** | 2025-09-09 | <details><summary>ICML ...</summary><p>ICML 2025; ICLR 2025 World Models Workshop (oral, outstanding paper award)</p></details> |
| **[Semi-SMD: Semi-Supervised Metric Depth Estimation via Surrounding Cameras for Autonomous Driving](http://arxiv.org/abs/2503.19713v3)** | 2025-09-09 |  |
| **[Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting](http://arxiv.org/abs/2506.19089v3)** | 2025-09-09 | 12 pages, 11 figures |
| **[LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](http://arxiv.org/abs/2509.05263v2)** | 2025-09-08 |  |
| **[Vanishing Stacked-Residual PINN for State Reconstruction of Hyperbolic Systems](http://arxiv.org/abs/2503.14222v5)** | 2025-09-08 |  |
| **[BriLLM: Brain-inspired Large Language Model](http://arxiv.org/abs/2503.11299v8)** | 2025-09-08 |  |
| **[CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis](http://arxiv.org/abs/2509.06579v1)** | 2025-09-08 |  |
| **[MAPF-World: Action World Model for Multi-Agent Path Finding](http://arxiv.org/abs/2508.12087v2)** | 2025-09-07 |  |
| **[Planning with Reasoning using Vision Language World Model](http://arxiv.org/abs/2509.02722v2)** | 2025-09-06 |  |
| **[RecPS: Privacy Risk Scoring for Recommender Systems](http://arxiv.org/abs/2507.18365v4)** | 2025-09-06 | <details><summary>Accep...</summary><p>Accepted by ACM RecSys 2025; to appear</p></details> |
| **[Offline vs. Online Learning in Model-based RL: Lessons for Data Collection Strategies](http://arxiv.org/abs/2509.05735v1)** | 2025-09-06 | <details><summary>Accep...</summary><p>Accepted at Reinforcement Learning Conference (RLC 2025); Code available at: https://github.com/swsychen/Offline_vs_Online_in_MBRL</p></details> |
| **[Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach](http://arxiv.org/abs/2505.16422v3)** | 2025-09-05 | <details><summary>Accep...</summary><p>Accepted to Findings of EMNLP 2025. This is the camera-ready version</p></details> |
| **[Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](http://arxiv.org/abs/2509.04731v1)** | 2025-09-05 |  |

