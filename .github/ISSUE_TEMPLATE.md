---
title: Latest 15 Papers - September 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs](http://arxiv.org/abs/2509.11480v1)** | 2025-09-15 | <details><summary>To ap...</summary><p>To appear in the Asilomar Conference on Signals, Systems, and Computers 2025</p></details> |
| **[Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations](http://arxiv.org/abs/2509.11417v1)** | 2025-09-14 | <details><summary>Proje...</summary><p>Project Page: https://gen-vla.github.io/</p></details> |
| **[SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](http://arxiv.org/abs/2509.09674v1)** | 2025-09-11 |  |
| **[VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model](http://arxiv.org/abs/2509.09372v1)** | 2025-09-11 |  |
| **[villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](http://arxiv.org/abs/2507.23682v2)** | 2025-09-11 | <details><summary>Proje...</summary><p>Project page: https://aka.ms/villa-x</p></details> |
| **[SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models](http://arxiv.org/abs/2509.09090v1)** | 2025-09-11 | 12 pages, 9 figures |
| **[RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation](http://arxiv.org/abs/2509.08820v1)** | 2025-09-10 | <details><summary>Accep...</summary><p>Accepted to CoRL 2025, Project Page: https://zzongzheng0918.github.io/RoboChemist.github.io/</p></details> |
| **[LLaDA-VLA: Vision Language Diffusion Action Models](http://arxiv.org/abs/2509.06932v2)** | 2025-09-10 |  |
| **[TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models](http://arxiv.org/abs/2509.07962v1)** | 2025-09-09 | <details><summary>Accep...</summary><p>Accepted to CoRL 2025, project page: \url{https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/}</p></details> |
| **[Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](http://arxiv.org/abs/2509.07957v1)** | 2025-09-09 | <details><summary>This ...</summary><p>This paper is submitted to IEEE IROS 2025 Workshop AIR4S</p></details> |
| **[EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](http://arxiv.org/abs/2508.21112v3)** | 2025-09-09 |  |
| **[F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](http://arxiv.org/abs/2509.06951v2)** | 2025-09-09 | <details><summary>Homep...</summary><p>Homepage: https://aopolin-lv.github.io/F1-VLA/</p></details> |
| **[CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](http://arxiv.org/abs/2509.06819v1)** | 2025-09-08 | 5 pages, 5 figures |
| **[Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy](http://arxiv.org/abs/2503.19757v2)** | 2025-09-06 | <details><summary>Prepr...</summary><p>Preprint; https://robodita.github.io; To appear in ICCV2025</p></details> |
| **[4D Visual Pre-training for Robot Learning](http://arxiv.org/abs/2508.17230v2)** | 2025-09-06 |  |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](http://arxiv.org/abs/2506.10968v2)** | 2025-09-15 | <details><summary>CoRL ...</summary><p>CoRL 2025, project page: https://www.eyerobot.net/</p></details> |
| **[Learning Precise Affordances from Egocentric Videos for Robotic Manipulation](http://arxiv.org/abs/2408.10123v2)** | 2025-09-15 | ICCV 2025 |
| **[Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees](http://arxiv.org/abs/2509.12008v1)** | 2025-09-15 |  |
| **[Time-Constrained Intelligent Adversaries for Automation Vulnerability Testing: A Multi-Robot Patrol Case Study](http://arxiv.org/abs/2509.11971v1)** | 2025-09-15 |  |
| **[Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer](http://arxiv.org/abs/2509.11865v1)** | 2025-09-15 | 8 pages, 4 figures |
| **[Augmented Reality-Enhanced Robot Teleoperation for Collecting User Demonstrations](http://arxiv.org/abs/2509.11783v1)** | 2025-09-15 | <details><summary>Accep...</summary><p>Accepted by 2025 8th International Conference on Robotics, Control and Automation Engineering (RCAE 2025)</p></details> |
| **[Time to Play: Simulating Early-Life Animal Dynamics Enhances Robotics Locomotion Discovery](http://arxiv.org/abs/2509.11755v1)** | 2025-09-15 |  |
| **[Microsurgical Instrument Segmentation for Robot-Assisted Surgery](http://arxiv.org/abs/2509.11727v1)** | 2025-09-15 | 8 pages, 7 figures |
| **[Anticipating Human Behavior for Safe Navigation and Efficient Collaborative Manipulation with Mobile Service Robots](http://arxiv.org/abs/2410.05015v2)** | 2025-09-15 |  |
| **[Gaussian path model library for intuitive robot motion programming by demonstration](http://arxiv.org/abs/2509.10007v2)** | 2025-09-15 |  |
| **[Robots that Evolve with Us: Modular Co-Design for Personalization, Adaptability, and Sustainability](http://arxiv.org/abs/2509.11622v1)** | 2025-09-15 | Pre-print |
| **[AssemMate: Graph-Based LLM for Robotic Assembly Assistance](http://arxiv.org/abs/2509.11617v1)** | 2025-09-15 |  |
| **[GBPP: Grasp-Aware Base Placement Prediction for Robots via Two-Stage Learning](http://arxiv.org/abs/2509.11594v1)** | 2025-09-15 | <details><summary>Jizhu...</summary><p>Jizhuo Chen and Diwen Liu contributed equally</p></details> |
| **[Shape control of simulated multi-segment continuum robots via Koopman operators with per-segment projection](http://arxiv.org/abs/2509.11567v1)** | 2025-09-15 | <details><summary>7 pag...</summary><p>7 pages (+2 pages of references), 8 figures</p></details> |
| **[Physics-informed Split Koopman Operators for Data-efficient Soft Robotic Simulation](http://arxiv.org/abs/2502.00162v2)** | 2025-09-15 | <details><summary>This ...</summary><p>This work has been submitted and accepted to ICRA 2025. Please see https://ieeexplore.ieee.org/document/11127545</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Open-ended Hierarchical Streaming Video Understanding with Vision Language Models](http://arxiv.org/abs/2509.12145v1)** | 2025-09-15 | 17 pages |
| **[Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models](http://arxiv.org/abs/2509.12132v1)** | 2025-09-15 | EMNLP2025 Main |
| **[Embodied Navigation Foundation Model](http://arxiv.org/abs/2509.12129v1)** | 2025-09-15 | <details><summary>Proje...</summary><p>Project Page: https://pku-epic.github.io/NavFoM-Web/</p></details> |
| **[Social Perception of Faces in a Vision-Language Model](http://arxiv.org/abs/2408.14435v2)** | 2025-09-15 |  |
| **[RISE: Enhancing VLM Image Annotation with Self-Supervised Reasoning](http://arxiv.org/abs/2508.13229v3)** | 2025-09-15 |  |
| **[Lost in Embeddings: Information Loss in Vision-Language Models](http://arxiv.org/abs/2509.11986v1)** | 2025-09-15 |  |
| **[Spec-LLaVA: Accelerating Vision-Language Models with Dynamic Tree-Based Speculative Decoding](http://arxiv.org/abs/2509.11961v1)** | 2025-09-15 | <details><summary>7page...</summary><p>7pages, accepted by ICML TTODLer-FM workshop</p></details> |
| **[Bridging Vision Language Models and Symbolic Grounding for Video Question Answering](http://arxiv.org/abs/2509.11862v1)** | 2025-09-15 |  |
| **[Synthetic Captions for Open-Vocabulary Zero-Shot Segmentation](http://arxiv.org/abs/2509.11840v1)** | 2025-09-15 | <details><summary>ICCV ...</summary><p>ICCV 2025 CDEL Workshop</p></details> |
| **[Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts](http://arxiv.org/abs/2501.15688v2)** | 2025-09-15 |  |
| **[SpecVLM: Fast Speculative Decoding in Vision-Language Models](http://arxiv.org/abs/2509.11815v1)** | 2025-09-15 |  |
| **[Igniting VLMs toward the Embodied Space](http://arxiv.org/abs/2509.11766v1)** | 2025-09-15 |  |
| **[EMeRALDS: Electronic Medical Record Driven Automated Lung Nodule Detection and Classification in Thoracic CT Images](http://arxiv.org/abs/2509.11714v1)** | 2025-09-15 |  |
| **[Towards Understanding Visual Grounding in Visual Language Models](http://arxiv.org/abs/2509.10345v2)** | 2025-09-15 |  |
| **[Remote Sensing SpatioTemporal Vision-Language Models: A Comprehensive Survey](http://arxiv.org/abs/2412.02573v3)** | 2025-09-15 | <details><summary>Publi...</summary><p>Published in IEEE Geoscience and Remote Sensing Magazine</p></details> |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling](http://arxiv.org/abs/2509.12201v1)** | 2025-09-15 | <details><summary>https...</summary><p>https://yangzhou24.github.io/OmniWorld/</p></details> |
| **[Learning to Generate 4D LiDAR Sequences](http://arxiv.org/abs/2509.11959v1)** | 2025-09-15 | <details><summary>Abstr...</summary><p>Abstract Paper (Non-Archival) @ ICCV 2025 Wild3D Workshop; GitHub Repo at https://lidarcrafter.github.io/</p></details> |
| **[Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](http://arxiv.org/abs/2509.11943v1)** | 2025-09-15 | <details><summary>10 pa...</summary><p>10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at NeuralIPS</p></details> |
| **[Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?](http://arxiv.org/abs/2509.10875v1)** | 2025-09-13 |  |
| **[Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models](http://arxiv.org/abs/2405.13798v4)** | 2025-09-12 |  |
| **[LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation](http://arxiv.org/abs/2505.11528v6)** | 2025-09-12 | CoRL 2025 |
| **[3D and 4D World Modeling: A Survey](http://arxiv.org/abs/2509.07996v2)** | 2025-09-11 | <details><summary>Surve...</summary><p>Survey; 34 pages, 10 figures, 14 tables; GitHub Repo at https://github.com/worldbench/survey</p></details> |
| **[World Modeling with Probabilistic Structure Integration](http://arxiv.org/abs/2509.09737v1)** | 2025-09-10 |  |
| **[Randomly Sampled Language Reasoning Problems Elucidate Limitations of In-Context Learning](http://arxiv.org/abs/2501.02825v6)** | 2025-09-10 | <details><summary>10 pa...</summary><p>10 pages, 4 figures, 2 tables</p></details> |
| **[A Survey of World Models for Autonomous Driving](http://arxiv.org/abs/2501.11260v4)** | 2025-09-10 | <details><summary>Ongoi...</summary><p>Ongoing project. Paper list: https://github.com/FengZicai/AwesomeWMAD Benchmark: https://github.com/FengZicai/WMAD-Benchmarks</p></details> |
| **[One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning](http://arxiv.org/abs/2509.07945v1)** | 2025-09-09 | 43 pages, 19 figures |
| **[LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences](http://arxiv.org/abs/2508.03692v2)** | 2025-09-09 | <details><summary>Prepr...</summary><p>Preprint; 28 pages, 18 figures, 12 tables; Project Page at https://lidarcrafter.github.io</p></details> |
| **[When Do Neural Networks Learn World Models?](http://arxiv.org/abs/2502.09297v5)** | 2025-09-09 | <details><summary>ICML ...</summary><p>ICML 2025; ICLR 2025 World Models Workshop (oral, outstanding paper award)</p></details> |
| **[Semi-SMD: Semi-Supervised Metric Depth Estimation via Surrounding Cameras for Autonomous Driving](http://arxiv.org/abs/2503.19713v3)** | 2025-09-09 |  |
| **[Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting](http://arxiv.org/abs/2506.19089v3)** | 2025-09-09 | 12 pages, 11 figures |

