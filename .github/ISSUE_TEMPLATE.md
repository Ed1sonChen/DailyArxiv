---
title: Latest 15 Papers - May 28, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Attacks against Closed-Source MLLMs via Feature Optimal Alignment](http://arxiv.org/abs/2505.21494v1)** | 2025-05-27 |  |
| **[AutoJudger: An Agent-Driven Framework for Efficient Benchmarking of MLLMs](http://arxiv.org/abs/2505.21389v1)** | 2025-05-27 |  |
| **[Video-Holmes: Can MLLM Think Like Holmes for Complex Video Reasoning?](http://arxiv.org/abs/2505.21374v1)** | 2025-05-27 | <details><summary>Homep...</summary><p>Homepage: https://github.com/TencentARC/Video-Holmes</p></details> |
| **[MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs](http://arxiv.org/abs/2505.21327v1)** | 2025-05-27 |  |
| **[MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness](http://arxiv.org/abs/2505.20426v1)** | 2025-05-26 |  |
| **[FullFront: Benchmarking MLLMs Across the Full Front-End Engineering Workflow](http://arxiv.org/abs/2505.17399v2)** | 2025-05-26 |  |
| **[MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning](http://arxiv.org/abs/2505.19714v1)** | 2025-05-26 | Work in progress |
| **[MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed Image Retrieval](http://arxiv.org/abs/2505.19707v1)** | 2025-05-26 |  |
| **[MIND-Edit: MLLM Insight-Driven Editing via Language-Vision Projection](http://arxiv.org/abs/2505.19149v1)** | 2025-05-25 |  |
| **[Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps](http://arxiv.org/abs/2505.18675v1)** | 2025-05-24 |  |
| **[MLLMs are Deeply Affected by Modality Bias](http://arxiv.org/abs/2505.18657v1)** | 2025-05-24 |  |
| **[Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](http://arxiv.org/abs/2505.11141v2)** | 2025-05-24 |  |
| **[The Coherence Trap: When MLLM-Crafted Narratives Exploit Manipulated Visual Contexts](http://arxiv.org/abs/2505.17476v1)** | 2025-05-23 |  |
| **[Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents](http://arxiv.org/abs/2505.14418v2)** | 2025-05-23 | <details><summary>25 pa...</summary><p>25 pages, 10 figures, 12 Tables</p></details> |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v4)** | 2025-05-22 |  |

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hume: Introducing System-2 Thinking in Visual-Language-Action Model](http://arxiv.org/abs/2505.21432v1)** | 2025-05-27 |  |
| **[Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models](http://arxiv.org/abs/2505.21200v1)** | 2025-05-27 |  |
| **[QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning](http://arxiv.org/abs/2412.15576v5)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted to ICRA 2025; Github page: https://quart-online.github.io</p></details> |
| **[From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation](http://arxiv.org/abs/2505.08548v2)** | 2025-05-27 | <details><summary>Our p...</summary><p>Our project homepage: https://embodied-fsd.github.io/</p></details> |
| **[RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation](http://arxiv.org/abs/2412.13877v3)** | 2025-05-27 | <details><summary>21 pa...</summary><p>21 pages, 17 figures, Robotics: Science and Systems 2025</p></details> |
| **[Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review](http://arxiv.org/abs/2505.20503v1)** | 2025-05-26 |  |
| **[What Can RL Bring to VLA Generalization? An Empirical Study](http://arxiv.org/abs/2505.19789v1)** | 2025-05-26 |  |
| **[RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback](http://arxiv.org/abs/2505.19767v1)** | 2025-05-26 |  |
| **[ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning](http://arxiv.org/abs/2505.19080v1)** | 2025-05-25 | 10 pages |
| **[RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction](http://arxiv.org/abs/2505.12224v3)** | 2025-05-25 |  |
| **[Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance](http://arxiv.org/abs/2505.18793v1)** | 2025-05-24 |  |
| **[Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization](http://arxiv.org/abs/2505.15660v2)** | 2025-05-24 | <details><summary>Proje...</summary><p>Project Page: https://jiaming-zhou.github.io/AGNOSTOS</p></details> |
| **[VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning](http://arxiv.org/abs/2505.18719v1)** | 2025-05-24 |  |
| **[ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems](http://arxiv.org/abs/2505.17295v1)** | 2025-05-22 | 17 pages, 11 figures |
| **[Interactive Post-Training for Vision-Language-Action Models](http://arxiv.org/abs/2505.17016v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project page: https://ariostgx.github.io/ript_vla/</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an open-source device for Multimodal robot Perception](http://arxiv.org/abs/2505.21495v1)** | 2025-05-27 |  |
| **[EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation](http://arxiv.org/abs/2505.21351v1)** | 2025-05-27 |  |
| **[EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild](http://arxiv.org/abs/2505.21282v1)** | 2025-05-27 |  |
| **[CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration](http://arxiv.org/abs/2403.18459v2)** | 2025-05-27 | <details><summary>7 pag...</summary><p>7 pages, 8 figures, accepted at IEEE IROS 2024</p></details> |
| **[Human-Centered Development of Guide Dog Robots: Quiet and Stable Locomotion Control](http://arxiv.org/abs/2505.11808v2)** | 2025-05-27 |  |
| **[Efficient Robotic Policy Learning via Latent Space Backward Planning](http://arxiv.org/abs/2505.06861v2)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning](http://arxiv.org/abs/2505.20962v1)** | 2025-05-27 |  |
| **[Spatial RoboGrasp: Generalized Robotic Grasping Control Policy](http://arxiv.org/abs/2505.20814v1)** | 2025-05-27 |  |
| **[Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt](http://arxiv.org/abs/2505.20795v1)** | 2025-05-27 |  |
| **[From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation](http://arxiv.org/abs/2505.08548v2)** | 2025-05-27 | <details><summary>Our p...</summary><p>Our project homepage: https://embodied-fsd.github.io/</p></details> |
| **[JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes](http://arxiv.org/abs/2505.06771v2)** | 2025-05-27 | <details><summary>22 pa...</summary><p>22 pages, 14 figures, 10 tables. https://github.com/GT-STAR-Lab/JaxRobotarium</p></details> |
| **[RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation](http://arxiv.org/abs/2412.13877v3)** | 2025-05-27 | <details><summary>21 pa...</summary><p>21 pages, 17 figures, Robotics: Science and Systems 2025</p></details> |
| **[Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners](http://arxiv.org/abs/2505.20573v1)** | 2025-05-26 |  |
| **[Developing a Robotic Surgery Training System for Wide Accessibility and Research](http://arxiv.org/abs/2505.20562v1)** | 2025-05-26 | <details><summary>6 pag...</summary><p>6 pages, The IEEE International Conference on Advanced Robotics and Mechatronics (IEEE ARM 2025), accepted</p></details> |
| **[CoRI: Synthesizing Communication of Robot Intent for Physical Human-Robot Interaction](http://arxiv.org/abs/2505.20537v1)** | 2025-05-26 | 33 pages, 10 figures |

## diffusion policy
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Diffusion Predictive Control with Constraints](http://arxiv.org/abs/2412.09342v2)** | 2025-05-27 | <details><summary>Accep...</summary><p>Accepted to L4DC 2025. Code: https://github.com/ralfroemer99/dpcc. 14 pages, 3 figures, 3 tables</p></details> |
| **[DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving](http://arxiv.org/abs/2505.19381v2)** | 2025-05-27 | 4pages |
| **[DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets](http://arxiv.org/abs/2505.18876v1)** | 2025-05-24 | <details><summary>Submi...</summary><p>Submitted to CoRL 2025</p></details> |
| **[GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning](http://arxiv.org/abs/2505.18763v1)** | 2025-05-24 |  |
| **[Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy](http://arxiv.org/abs/2505.17434v1)** | 2025-05-23 | 11 pages, |
| **[3D Equivariant Visuomotor Policy Learning via Spherical Projection](http://arxiv.org/abs/2505.16969v1)** | 2025-05-22 |  |
| **[Safe Uncertainty-Aware Learning of Robotic Suturing](http://arxiv.org/abs/2505.16596v1)** | 2025-05-22 |  |
| **[Cascaded Diffusion Models for Neural Motion Planning](http://arxiv.org/abs/2505.15157v1)** | 2025-05-21 | ICRA'25 |
| **[A Practical Guide for Incorporating Symmetry in Diffusion Policy](http://arxiv.org/abs/2505.13431v2)** | 2025-05-20 |  |
| **[Learning to Group and Grasp Multiple Objects](http://arxiv.org/abs/2502.08452v2)** | 2025-05-20 |  |
| **[Learning Long-Context Diffusion Policies via Past-Token Prediction](http://arxiv.org/abs/2505.09561v2)** | 2025-05-19 | <details><summary>Video...</summary><p>Videos are available at https://long-context-dp.github.io</p></details> |
| **[MTIL: Encoding Full History with Mamba for Temporal Imitation Learning](http://arxiv.org/abs/2505.12410v1)** | 2025-05-18 | <details><summary>16 pa...</summary><p>16 pages,6 figures,Submitted to IEEE RAL</p></details> |
| **[Zero-Shot Visual Generalization in Robot Manipulation](http://arxiv.org/abs/2505.11719v1)** | 2025-05-16 |  |
| **[Fast and Robust Visuomotor Riemannian Flow Matching Policy](http://arxiv.org/abs/2412.10855v2)** | 2025-05-16 | <details><summary>17 pa...</summary><p>17 pages, 12 figures, 12 tables, project website: https://sites.google.com/view/rfmp</p></details> |
| **[Exploratory Diffusion Model for Unsupervised Reinforcement Learning](http://arxiv.org/abs/2502.07279v2)** | 2025-05-16 |  |

