---
title: Latest 15 Papers - May 11, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](http://arxiv.org/abs/2505.02064v2)** | 2025-05-06 | <details><summary>13 pa...</summary><p>13 pages, 4 figures, 5 tables</p></details> |
| **[MLLM-Enhanced Face Forgery Detection: A Vision-Language Fusion Solution](http://arxiv.org/abs/2505.02013v1)** | 2025-05-04 |  |
| **[Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](http://arxiv.org/abs/2504.21277v1)** | 2025-04-30 |  |
| **[Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](http://arxiv.org/abs/2505.00742v1)** | 2025-04-30 |  |
| **[Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs](http://arxiv.org/abs/2504.15280v2)** | 2025-04-27 | <details><summary>Proje...</summary><p>Project page: https://danielchyeh.github.io/All-Angles-Bench/</p></details> |
| **[ZipR1: Reinforcing Token Sparsity in MLLMs](http://arxiv.org/abs/2504.18579v1)** | 2025-04-23 | work in process |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v3)** | 2025-04-21 |  |
| **[A Call for New Recipes to Enhance Spatial Reasoning in MLLMs](http://arxiv.org/abs/2504.15037v1)** | 2025-04-21 |  |
| **[CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography](http://arxiv.org/abs/2504.10090v2)** | 2025-04-17 |  |
| **[EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand Multi-Source Remote Sensing Imagery](http://arxiv.org/abs/2504.12795v1)** | 2025-04-17 |  |
| **[Look Before You Decide: Prompting Active Deduction of MLLMs for Assumptive Reasoning](http://arxiv.org/abs/2404.12966v5)** | 2025-04-17 |  |
| **[AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection](http://arxiv.org/abs/2504.11914v1)** | 2025-04-16 |  |
| **[Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation](http://arxiv.org/abs/2504.11002v1)** | 2025-04-15 |  |
| **[Foundation Models for Remote Sensing: An Analysis of MLLMs for Object Localization](http://arxiv.org/abs/2504.10727v1)** | 2025-04-14 | <details><summary>26 pa...</summary><p>26 pages, CVPR MORSE Workshop 2025</p></details> |
| **[The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance](http://arxiv.org/abs/2504.10179v1)** | 2025-04-14 |  |

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Vision-Language-Action Models: Concepts, Progress, Applications and Challenges](http://arxiv.org/abs/2505.04769v1)** | 2025-05-07 | <details><summary>36 pa...</summary><p>36 pages, 18 Figures, 4 Tables</p></details> |
| **[OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation](http://arxiv.org/abs/2505.03912v1)** | 2025-05-06 |  |
| **[Task Reconstruction and Extrapolation for $π_0$ using Text Latent](http://arxiv.org/abs/2505.03500v1)** | 2025-05-06 |  |
| **[GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data](http://arxiv.org/abs/2505.03233v1)** | 2025-05-06 |  |
| **[Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets](http://arxiv.org/abs/2505.03174v1)** | 2025-05-06 |  |
| **[CrayonRobo: Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation](http://arxiv.org/abs/2505.02166v1)** | 2025-05-04 | CVPR 2025 |
| **[Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions](http://arxiv.org/abs/2505.02152v1)** | 2025-05-04 |  |
| **[NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks](http://arxiv.org/abs/2504.19854v1)** | 2025-04-28 |  |
| **[Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success](http://arxiv.org/abs/2502.19645v2)** | 2025-04-28 | <details><summary>Accep...</summary><p>Accepted to Robotics: Science and Systems (RSS) 2025. Project website: https://openvla-oft.github.io/</p></details> |
| **[QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning](http://arxiv.org/abs/2412.15576v4)** | 2025-04-24 | <details><summary>Accep...</summary><p>Accepted to ICRA 2025; Github page: https://quart-online.github.io</p></details> |
| **[$π_{0.5}$: a Vision-Language-Action Model with Open-World Generalization](http://arxiv.org/abs/2504.16054v1)** | 2025-04-22 |  |
| **[Few-Shot Vision-Language Action-Incremental Policy Learning](http://arxiv.org/abs/2504.15517v1)** | 2025-04-22 |  |
| **[GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents](http://arxiv.org/abs/2504.10458v3)** | 2025-04-18 |  |
| **[MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation](http://arxiv.org/abs/2503.20384v2)** | 2025-04-14 |  |
| **[ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy](http://arxiv.org/abs/2502.05450v2)** | 2025-04-14 |  |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[An End-to-End Framework for Optimizing Foot Trajectory and Force in Dry Adhesion Legged Wall-Climbing Robots](http://arxiv.org/abs/2504.19448v2)** | 2025-05-08 |  |
| **[Fast Whole-Body Strain Regulation in Continuum Robots](http://arxiv.org/abs/2312.06039v3)** | 2025-05-08 |  |
| **[CottonSim: Development of an autonomous visual-guided robotic cotton-picking system in the Gazebo](http://arxiv.org/abs/2505.05317v1)** | 2025-05-08 | <details><summary>45 pa...</summary><p>45 pages, 15 figures, 4 tables</p></details> |
| **[Visual Affordances: Enabling Robots to Understand Object Functionality](http://arxiv.org/abs/2505.05074v1)** | 2025-05-08 | <details><summary>24 pa...</summary><p>24 pages, 12 figures, 10 tables. Project website at https://apicis.github.io/aff-survey/</p></details> |
| **[FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment](http://arxiv.org/abs/2504.08603v2)** | 2025-05-08 | 11 pages, 5 figures |
| **[CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations](http://arxiv.org/abs/2505.04999v1)** | 2025-05-08 | <details><summary>Laten...</summary><p>Latent Action Models, Self-supervised Pretraining, Learning from Videos</p></details> |
| **[SatAOI: Delimitating Area of Interest for Swing-Arm Troweling Robot for Construction](http://arxiv.org/abs/2505.04871v1)** | 2025-05-08 |  |
| **[FieldNet: Efficient Real-Time Shadow Removal for Enhanced Vision in Field Robotics](http://arxiv.org/abs/2403.08142v2)** | 2025-05-08 | <details><summary>22 pa...</summary><p>22 pages, 9 figures, 8 tables. Published at Expert Systems with Applications</p></details> |
| **[Simplification of Robotic System Model Analysis by Petri Net Meta-Model Property Transfer](http://arxiv.org/abs/2407.06454v4)** | 2025-05-07 | 16 pages |
| **[Fitts' List Revisited: An Empirical Study on Function Allocation in a Two-Agent Physical Human-Robot Collaborative Position/Force Task](http://arxiv.org/abs/2505.04722v1)** | 2025-05-07 | <details><summary>10 pa...</summary><p>10 pages, 6 figures, under review for publication in IEEE Robotics and Automation Letters (RA-L)</p></details> |
| **[Stow: Robotic Packing of Items into Fabric Pods](http://arxiv.org/abs/2505.04572v1)** | 2025-05-07 |  |
| **[Accelerating Audio Research with Robotic Dummy Heads](http://arxiv.org/abs/2505.04548v1)** | 2025-05-07 | WASPAA 2025 |
| **[Model-Based AI planning and Execution Systems for Robotics](http://arxiv.org/abs/2505.04493v1)** | 2025-05-07 |  |
| **[Estimating Dynamic Soft Continuum Robot States From Boundaries](http://arxiv.org/abs/2505.04491v1)** | 2025-05-07 |  |
| **[Multi-Robot Motion Planning with Diffusion Models](http://arxiv.org/abs/2410.03072v2)** | 2025-05-07 | <details><summary>The f...</summary><p>The first three authors contributed equally to this work. Published at ICLR 2025</p></details> |

## diffusion policy
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models](http://arxiv.org/abs/2503.01876v2)** | 2025-05-08 |  |
| **[Close-Fitting Dressing Assistance Based on State Estimation of Feet and Garments with Semantic-based Visual Attention](http://arxiv.org/abs/2505.03400v1)** | 2025-05-06 |  |
| **[ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies](http://arxiv.org/abs/2502.18438v2)** | 2025-05-06 | <details><summary>Appea...</summary><p>Appears in Proc. of the Adaptive and Learning Agents Workshop (ALA 2025), ala-workshop.github.io</p></details> |
| **[Fast Flow-based Visuomotor Policies via Conditional Optimal Transport Couplings](http://arxiv.org/abs/2505.01179v1)** | 2025-05-02 |  |
| **[RoboBERT: An End-to-end Multimodal Robotic Manipulation Model](http://arxiv.org/abs/2502.07837v2)** | 2025-05-01 |  |
| **[PRISM-DP: Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking](http://arxiv.org/abs/2504.20359v2)** | 2025-05-01 |  |
| **[Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success](http://arxiv.org/abs/2502.19645v2)** | 2025-04-28 | <details><summary>Accep...</summary><p>Accepted to Robotics: Science and Systems (RSS) 2025. Project website: https://openvla-oft.github.io/</p></details> |
| **[PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies](http://arxiv.org/abs/2504.19341v1)** | 2025-04-27 | <details><summary>Nomin...</summary><p>Nominated for the best paper award at ICRA 2025</p></details> |
| **[You Only Teach Once: Learn One-Shot Bimanual Robotic Manipulation from Video Demonstrations](http://arxiv.org/abs/2501.14208v2)** | 2025-04-27 | accepted by RSS 2025 |
| **[DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories](http://arxiv.org/abs/2502.15043v2)** | 2025-04-26 |  |
| **[Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training](http://arxiv.org/abs/2502.03822v3)** | 2025-04-26 | <details><summary>Accep...</summary><p>Accepted to Robotics: Science and Systems (RSS) 2025</p></details> |
| **[Enhancing Exploration with Diffusion Policies in Hybrid Off-Policy RL: Application to Non-Prehensile Manipulation](http://arxiv.org/abs/2411.14913v2)** | 2025-04-25 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Robotics and Automation Letters (RA-L)</p></details> |
| **[Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation](http://arxiv.org/abs/2503.02881v3)** | 2025-04-23 | <details><summary>Accep...</summary><p>Accepted to RSS 2025. Project page: https://reactive-diffusion-policy.github.io</p></details> |
| **[Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction](http://arxiv.org/abs/2504.14588v1)** | 2025-04-20 | Accepted by CVPR2025 |
| **[The Pitfalls of Imitation Learning when Actions are Continuous](http://arxiv.org/abs/2503.09722v3)** | 2025-04-15 | <details><summary>98 pa...</summary><p>98 pages, 2 figures, updated proof sketch</p></details> |

