---
title: Latest 15 Papers - September 24, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Pure Vision Language Action (VLA) Models: A Comprehensive Survey](http://arxiv.org/abs/2509.19012v1)** | 2025-09-23 |  |
| **[Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations](http://arxiv.org/abs/2509.18953v1)** | 2025-09-23 |  |
| **[Latent Action Pretraining Through World Modeling](http://arxiv.org/abs/2509.18428v1)** | 2025-09-22 |  |
| **[GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](http://arxiv.org/abs/2509.14117v2)** | 2025-09-22 | Under Review |
| **[VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model](http://arxiv.org/abs/2509.09372v2)** | 2025-09-22 | <details><summary>28 pa...</summary><p>28 pages; Project page: https://vla-adapter.github.io/; Github: https://github.com/OpenHelix-Team/VLA-Adapter; HuggingFace: https://huggingface.co/VLA-Adapter</p></details> |
| **[The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](http://arxiv.org/abs/2509.12594v2)** | 2025-09-21 | <details><summary>Under...</summary><p>Under review. Project site: https://liauto-research.github.io/LightVLA</p></details> |
| **[Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse](http://arxiv.org/abs/2506.07639v2)** | 2025-09-21 |  |
| **[Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance](http://arxiv.org/abs/2507.22424v2)** | 2025-09-20 | <details><summary>13 pa...</summary><p>13 pages, 5 figures, Accepted by EMNLP 2025 (main conference)</p></details> |
| **[Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding](http://arxiv.org/abs/2507.00416v2)** | 2025-09-20 |  |
| **[CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine](http://arxiv.org/abs/2509.15968v1)** | 2025-09-19 |  |
| **[A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning](http://arxiv.org/abs/2509.15937v1)** | 2025-09-19 | 26 pages,10 figures |
| **[RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation](http://arxiv.org/abs/2509.15212v1)** | 2025-09-18 | <details><summary>GitHu...</summary><p>GitHub Project: https://github.com/alibaba-damo-academy/RynnVLA-001</p></details> |
| **[Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models](http://arxiv.org/abs/2409.13174v3)** | 2025-09-18 |  |
| **[ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](http://arxiv.org/abs/2507.16815v2)** | 2025-09-18 | <details><summary>NeurI...</summary><p>NeurIPS 2025. Project page: https://jasper0314-huang.github.io/thinkact-vla/</p></details> |
| **[ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation](http://arxiv.org/abs/2505.22159v3)** | 2025-09-18 | NeurIPS 2025 |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration](http://arxiv.org/abs/2509.19292v1)** | 2025-09-23 |  |
| **[Proactive-reactive detection and mitigation of intermittent faults in robot swarms](http://arxiv.org/abs/2509.19246v1)** | 2025-09-23 |  |
| **[Occlusion-Aware Consistent Model Predictive Control for Robot Navigation in Occluded Obstacle-Dense Environments](http://arxiv.org/abs/2503.04563v3)** | 2025-09-23 |  |
| **[MagiClaw: A Dual-Use, Vision-Based Soft Gripper for Bridging the Human Demonstration to Robotic Deployment Gap](http://arxiv.org/abs/2509.19169v1)** | 2025-09-23 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, accepted to Data@CoRL2025 Workshop</p></details> |
| **[A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](http://arxiv.org/abs/2509.19168v1)** | 2025-09-23 | 8 Pages, 7 Figures |
| **[Socially Pertinent Robots in Gerontological Healthcare](http://arxiv.org/abs/2404.07560v3)** | 2025-09-23 |  |
| **[FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](http://arxiv.org/abs/2509.19102v1)** | 2025-09-23 | <details><summary>proje...</summary><p>project website: https://sites.google.com/view/funcanon, 11 pages</p></details> |
| **[World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](http://arxiv.org/abs/2509.19080v1)** | 2025-09-23 |  |
| **[SlicerROS2: A Research and Development Module for Image-Guided Robotic Interventions](http://arxiv.org/abs/2509.19076v1)** | 2025-09-23 |  |
| **[Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation](http://arxiv.org/abs/2509.17204v2)** | 2025-09-23 | 8 pages |
| **[Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning](http://arxiv.org/abs/2506.05985v2)** | 2025-09-23 |  |
| **[Lang2Morph: Language-Driven Morphological Design of Robotic Hands](http://arxiv.org/abs/2509.18937v1)** | 2025-09-23 |  |
| **[Cybersecurity AI: Humanoid Robots as Attack Vectors](http://arxiv.org/abs/2509.14139v3)** | 2025-09-23 |  |
| **[Enhancing Video-Based Robot Failure Detection Using Task Knowledge](http://arxiv.org/abs/2508.18705v2)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted at ECMR 2025</p></details> |
| **[DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](http://arxiv.org/abs/2509.18830v1)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted to CoRL 2025</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](http://arxiv.org/abs/2509.19274v1)** | 2025-09-23 | EMNLP MAINS 2025 |
| **[Leveraging Large Models to Evaluate Novel Content: A Case Study on Advertisement Creativity](http://arxiv.org/abs/2503.00046v2)** | 2025-09-23 | <details><summary>To Ap...</summary><p>To Appear in EMNLP2025</p></details> |
| **[Token Preference Optimization with Self-Calibrated Visual-Anchored Rewards for Hallucination Mitigation](http://arxiv.org/abs/2412.14487v4)** | 2025-09-23 |  |
| **[Large Vision-Language Model Alignment and Misalignment: A Survey Through the Lens of Explainability](http://arxiv.org/abs/2501.01346v3)** | 2025-09-23 | EMNLP 2025 Findings |
| **[Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](http://arxiv.org/abs/2509.19207v1)** | 2025-09-23 |  |
| **[Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](http://arxiv.org/abs/2509.19203v1)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted at EMNLP 2025</p></details> |
| **[Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](http://arxiv.org/abs/2509.19191v1)** | 2025-09-23 |  |
| **[Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study](http://arxiv.org/abs/2505.15389v3)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025</p></details> |
| **[VLDBench Evaluating Multimodal Disinformation with Regulatory Alignment](http://arxiv.org/abs/2502.11361v4)** | 2025-09-23 | under review |
| **[FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](http://arxiv.org/abs/2509.19102v1)** | 2025-09-23 | <details><summary>proje...</summary><p>project website: https://sites.google.com/view/funcanon, 11 pages</p></details> |
| **[ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](http://arxiv.org/abs/2509.19070v1)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted at the Open Science for Foundation Models (SCI-FM) Workshop at ICLR 2025</p></details> |
| **[CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning](http://arxiv.org/abs/2503.18672v7)** | 2025-09-23 |  |
| **[Pure Vision Language Action (VLA) Models: A Comprehensive Survey](http://arxiv.org/abs/2509.19012v1)** | 2025-09-23 |  |
| **[Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](http://arxiv.org/abs/2509.19003v1)** | 2025-09-23 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning](http://arxiv.org/abs/2509.18938v1)** | 2025-09-23 | <details><summary>This ...</summary><p>This paper was accepted at International Conference on Tools with Artificial Intelligence (ICTAI) 2025</p></details> |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PIGDreamer: Privileged Information Guided World Models for Safe Partially Observable Reinforcement Learning](http://arxiv.org/abs/2508.02159v2)** | 2025-09-23 | ICML 2025 |
| **[Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding](http://arxiv.org/abs/2501.17310v4)** | 2025-09-23 |  |
| **[World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](http://arxiv.org/abs/2509.19080v1)** | 2025-09-23 |  |
| **[Program Synthesis via Test-Time Transduction](http://arxiv.org/abs/2509.17393v2)** | 2025-09-23 | NeurIPS 2025 |
| **[Latent Action Pretraining Through World Modeling](http://arxiv.org/abs/2509.18428v1)** | 2025-09-22 |  |
| **[Remote Sensing-Oriented World Model](http://arxiv.org/abs/2509.17808v1)** | 2025-09-22 | 10 pages, 5 figures |
| **[Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](http://arxiv.org/abs/2507.13340v2)** | 2025-09-21 |  |
| **[Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](http://arxiv.org/abs/2508.20840v2)** | 2025-09-20 |  |
| **[Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds](http://arxiv.org/abs/2509.15915v1)** | 2025-09-19 | <details><summary>20 pa...</summary><p>20 pages, 9 figures. Accepted for presentation at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on Embodied World Models for Decision Making</p></details> |
| **[World Modelling Improves Language Model Agents](http://arxiv.org/abs/2506.02918v2)** | 2025-09-19 |  |
| **[SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models](http://arxiv.org/abs/2509.15536v1)** | 2025-09-19 | 22 pages,15 figures |
| **[OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data](http://arxiv.org/abs/2509.15479v1)** | 2025-09-18 |  |
| **[GAF: Gaussian Action Field as a Dynamic World Model for Robotic Manipulation](http://arxiv.org/abs/2506.14135v3)** | 2025-09-18 | <details><summary>http:...</summary><p>http://chaiying1.github.io/GAF.github.io/project_page/</p></details> |
| **[Designing Latent Safety Filters using Pre-Trained Vision Models](http://arxiv.org/abs/2509.14758v1)** | 2025-09-18 |  |
| **[Brain Inspired Probabilistic Occupancy Grid Mapping with Vector Symbolic Architectures](http://arxiv.org/abs/2408.09066v4)** | 2025-09-17 |  |

