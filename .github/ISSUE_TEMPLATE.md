---
title: Latest 15 Papers - November 26, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633v1)** | 2025-11-25 | <details><summary>https...</summary><p>https://LogosRoboticsGroup.github.io/ProphRL</p></details> |
| **[ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330v1)** | 2025-11-25 |  |
| **[GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430v2)** | 2025-11-25 | <details><summary>https...</summary><p>https://gigabrain0.github.io/</p></details> |
| **[Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving](https://arxiv.org/abs/2511.19912v1)** | 2025-11-25 |  |
| **[MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization](https://arxiv.org/abs/2511.19878v1)** | 2025-11-25 |  |
| **[GigaWorld-0: World Models as Data Engine to Empower Embodied AI](https://arxiv.org/abs/2511.19861v1)** | 2025-11-25 | <details><summary>Proje...</summary><p>Project Page: https://gigaworld0.github.io/</p></details> |
| **[Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859v1)** | 2025-11-25 |  |
| **[Continually Evolving Skill Knowledge in Vision Language Action Model](https://arxiv.org/abs/2511.18085v2)** | 2025-11-25 |  |
| **[Vision Language Models Can Parse Floor Plan Maps](https://arxiv.org/abs/2409.12842v2)** | 2025-11-24 |  |
| **[Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering](https://arxiv.org/abs/2511.19768v1)** | 2025-11-24 | <details><summary>webpa...</summary><p>webpage: https://noahfrahm.github.io/Prune-Then-Plan-project-page/</p></details> |
| **[Mixture of Horizons in Action Chunking](https://arxiv.org/abs/2511.19433v1)** | 2025-11-24 | 15 pages, 14 figures |
| **[Rethinking Intermediate Representation for VLM-based Robot Manipulation](https://arxiv.org/abs/2511.19315v1)** | 2025-11-24 |  |
| **[Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2511.19221v1)** | 2025-11-24 |  |
| **[Adapting Vision-Language Models for Evaluating World Models](https://arxiv.org/abs/2506.17967v2)** | 2025-11-24 | <details><summary>NeurI...</summary><p>NeurIPS LAW 2025 (Oral)</p></details> |
| **[Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding](https://arxiv.org/abs/2507.00416v3)** | 2025-11-24 |  |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning](https://arxiv.org/abs/2511.20593v1)** | 2025-11-25 |  |
| **[Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics](https://arxiv.org/abs/2511.20570v1)** | 2025-11-25 | <details><summary>Embod...</summary><p>Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025</p></details> |
| **[Kleinkram: Open Robotic Data Management](https://arxiv.org/abs/2511.20492v1)** | 2025-11-25 | <details><summary>for a...</summary><p>for associated source code, see https://github.com/leggedrobotics/kleinkram</p></details> |
| **[Power-Efficient Autonomous Mobile Robots](https://arxiv.org/abs/2511.20467v1)** | 2025-11-25 | 13 pages, 16 figures |
| **[How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299v1)** | 2025-11-25 |  |
| **[SafePR: Unified Approach for Safe Parallel Robots by Contact Detection and Reaction with Redundancy Resolution](https://arxiv.org/abs/2501.17773v3)** | 2025-11-25 |  |
| **[Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226v1)** | 2025-11-25 |  |
| **[ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955v1)** | 2025-11-25 |  |
| **[Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859v1)** | 2025-11-25 |  |
| **[Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation](https://arxiv.org/abs/2511.19647v1)** | 2025-11-24 |  |
| **[Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics](https://arxiv.org/abs/2501.10100v4)** | 2025-11-24 |  |
| **[Rethinking Intermediate Representation for VLM-based Robot Manipulation](https://arxiv.org/abs/2511.19315v1)** | 2025-11-24 |  |
| **[Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework](https://arxiv.org/abs/2511.19094v1)** | 2025-11-24 | <details><summary>MDPI ...</summary><p>MDPI Sensors, published 22 November 2025</p></details> |
| **[A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543v1)** | 2025-11-24 |  |
| **[M2R2: MultiModal Robotic Representation for Temporal Action Segmentation](https://arxiv.org/abs/2504.18662v2)** | 2025-11-24 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, 2 tables</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight](https://arxiv.org/abs/2511.20648v1)** | 2025-11-25 | <details><summary>Tech ...</summary><p>Tech report. Project page: https://nvlabs.github.io/LocateAnything3D/</p></details> |
| **[Vision-Language Memory for Spatial Reasoning](https://arxiv.org/abs/2511.20644v1)** | 2025-11-25 |  |
| **[Concept-Aware Batch Sampling Improves Language-Image Pretraining](https://arxiv.org/abs/2511.20643v1)** | 2025-11-25 | Tech Report |
| **[Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition](https://arxiv.org/abs/2511.20641v1)** | 2025-11-25 |  |
| **[Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633v1)** | 2025-11-25 | <details><summary>https...</summary><p>https://LogosRoboticsGroup.github.io/ProphRL</p></details> |
| **[Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems](https://arxiv.org/abs/2511.20627v1)** | 2025-11-25 |  |
| **[FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions](https://arxiv.org/abs/2509.17177v3)** | 2025-11-25 | <details><summary>Proje...</summary><p>Project homepage: https://flageval-baai.github.io/LRM-Eval/ This work will also be presented at NeurIPS 2025 Workshop on Foundations of Reasoning in Language Models (FoRLM); update with trials on Gemini 3 Pro</p></details> |
| **[AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations](https://arxiv.org/abs/2511.18617v2)** | 2025-11-25 | <details><summary>8 pag...</summary><p>8 pages, 6 figures. Code and datasets available at http://autofocus-il.github.io/</p></details> |
| **[Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models](https://arxiv.org/abs/2511.20531v1)** | 2025-11-25 | <details><summary>Accep...</summary><p>Accepted as poster at NewInML Workshop ICML, 2025</p></details> |
| **[ExDDV: A New Dataset for Explainable Deepfake Detection in Video](https://arxiv.org/abs/2503.14421v2)** | 2025-11-25 | <details><summary>Accep...</summary><p>Accepted at WACV 2026</p></details> |
| **[Adam Simplified: Bias Correction Simplified](https://arxiv.org/abs/2511.20516v1)** | 2025-11-25 |  |
| **[NVIDIA Nemotron Parse 1.1](https://arxiv.org/abs/2511.20478v1)** | 2025-11-25 |  |
| **[When to Think and When to Look: Uncertainty-Guided Lookback](https://arxiv.org/abs/2511.15613v2)** | 2025-11-25 |  |
| **[Object-Centric Vision Token Pruning for Vision Language Models](https://arxiv.org/abs/2511.20439v1)** | 2025-11-25 |  |
| **[VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422v1)** | 2025-11-25 |  |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cloud4D: Estimating Cloud Properties at a High Spatial and Temporal Resolution](https://arxiv.org/abs/2511.19431v2)** | 2025-11-25 | <details><summary>NeurI...</summary><p>NeurIPS 2025 Spotlight, project page: https://cloud4d.jacob-lin.com/</p></details> |
| **[LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight](https://arxiv.org/abs/2511.20648v1)** | 2025-11-25 | <details><summary>Tech ...</summary><p>Tech report. Project page: https://nvlabs.github.io/LocateAnything3D/</p></details> |
| **[Rethinking the Learning Paradigm for Facial Expression Recognition](https://arxiv.org/abs/2209.15402v3)** | 2025-11-25 |  |
| **[Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition](https://arxiv.org/abs/2511.20641v1)** | 2025-11-25 |  |
| **[Planning in Branch-and-Bound: Model-Based Reinforcement Learning for Exact Combinatorial Optimization](https://arxiv.org/abs/2511.09219v3)** | 2025-11-25 |  |
| **[Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633v1)** | 2025-11-25 | <details><summary>https...</summary><p>https://LogosRoboticsGroup.github.io/ProphRL</p></details> |
| **[Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI](https://arxiv.org/abs/2511.20620v1)** | 2025-11-25 |  |
| **[Discovering Spatial Patterns of Readmission Risk Using a Bayesian Competing Risks Model with Spatially Varying Coefficients](https://arxiv.org/abs/2511.20616v1)** | 2025-11-25 |  |
| **[Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning](https://arxiv.org/abs/2511.20613v1)** | 2025-11-25 |  |
| **[Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition](https://arxiv.org/abs/2511.20612v1)** | 2025-11-25 |  |
| **[How to Purchase Labels? A Cost-Effective Approach Using Active Learning Markets](https://arxiv.org/abs/2511.20605v1)** | 2025-11-25 | <details><summary>Submi...</summary><p>Submitted as a preprint. 34 pages, 14 figures, 4 tables</p></details> |
| **[Towards Multimodal Graph Large Language Model](https://arxiv.org/abs/2506.09738v2)** | 2025-11-25 | 4 figures, 2 tables |
| **[BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents](https://arxiv.org/abs/2511.20597v1)** | 2025-11-25 |  |
| **[PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic](https://arxiv.org/abs/2511.20586v1)** | 2025-11-25 |  |
| **[MSTN: Fast and Efficient Multivariate Time Series Model](https://arxiv.org/abs/2511.20577v1)** | 2025-11-25 | <details><summary>21 pa...</summary><p>21 pages, 1 figure, 5 tables</p></details> |

