---
title: Latest 15 Papers - October 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](http://arxiv.org/abs/2510.25713v1)** | 2025-10-29 |  |
| **[Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](http://arxiv.org/abs/2510.25616v1)** | 2025-10-29 | 13 pages, 6 figures |
| **[RoboOmni: Proactive Robot Manipulation in Omni-modal Context](http://arxiv.org/abs/2510.23763v2)** | 2025-10-29 |  |
| **[FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving](http://arxiv.org/abs/2505.17685v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025 as Spotlight Presentation. Code: https://github.com/MIV-XJTU/FSDrive</p></details> |
| **[RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](http://arxiv.org/abs/2506.06677v2)** | 2025-10-29 | <details><summary>25 pa...</summary><p>25 pages, 18 figures, Accepted by NeurIPS 2025</p></details> |
| **[NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](http://arxiv.org/abs/2510.25122v1)** | 2025-10-29 |  |
| **[Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](http://arxiv.org/abs/2508.20072v2)** | 2025-10-28 | 16 pages |
| **[On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations](http://arxiv.org/abs/2510.00037v3)** | 2025-10-28 |  |
| **[BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](http://arxiv.org/abs/2510.24161v1)** | 2025-10-28 |  |
| **[Learning to See and Act: Task-Aware View Planning for Robotic Manipulation](http://arxiv.org/abs/2508.05186v3)** | 2025-10-28 | <details><summary>14 pa...</summary><p>14 pages, 8 figures, project page: https://hcplab-sysu.github.io/TAVP</p></details> |
| **[A Survey on Efficient Vision-Language-Action Models](http://arxiv.org/abs/2510.24795v1)** | 2025-10-27 | 26 pages, 8 figures |
| **[UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](http://arxiv.org/abs/2510.23576v1)** | 2025-10-27 |  |
| **[Dexbotic: Open-Source Vision-Language-Action Toolbox](http://arxiv.org/abs/2510.23511v1)** | 2025-10-27 | <details><summary>Autho...</summary><p>Authors are listed in alphabetical order. The official website is located at https://dexbotic.com/. Code is available at https://github.com/Dexmal/dexbotic</p></details> |
| **[World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](http://arxiv.org/abs/2509.24948v2)** | 2025-10-27 |  |
| **[FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models](http://arxiv.org/abs/2510.01642v2)** | 2025-10-27 | <details><summary>Proje...</summary><p>Project Page: https://jimntu.github.io/FailSafe</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Modeling Collapse of Steered Vine Robots Under Their Own Weight](http://arxiv.org/abs/2510.25727v1)** | 2025-10-29 |  |
| **[Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](http://arxiv.org/abs/2510.25713v1)** | 2025-10-29 |  |
| **[RobEthiChor: Automated Context-aware Ethics-based Negotiation for Autonomous Robots](http://arxiv.org/abs/2507.22664v2)** | 2025-10-29 |  |
| **[RoboOmni: Proactive Robot Manipulation in Omni-modal Context](http://arxiv.org/abs/2510.23763v2)** | 2025-10-29 |  |
| **[Solving the Right Problem with Multi-Robot Formations](http://arxiv.org/abs/2510.25422v1)** | 2025-10-29 | <details><summary>Submi...</summary><p>Submitted to SAE WCX 2026</p></details> |
| **[Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](http://arxiv.org/abs/2510.21758v3)** | 2025-10-29 |  |
| **[To what extent can current French mobile network support agricultural robots?](http://arxiv.org/abs/2505.10044v4)** | 2025-10-29 | <details><summary>Best ...</summary><p>Best Paper ICT4S 2025</p></details> |
| **[Geometric Robot Calibration Using a Calibration Plate](http://arxiv.org/abs/2510.25338v1)** | 2025-10-29 | pp 309-317 |
| **[Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](http://arxiv.org/abs/2510.25280v1)** | 2025-10-29 |  |
| **[Multi-robot Motion Planning based on Nets-within-Nets Modeling and Simulation](http://arxiv.org/abs/2304.08772v4)** | 2025-10-29 | <details><summary>[Note...</summary><p>[Note for readers] This paper has been extended from a previous submission to 62nd IEEE Conference on Decision and Control, Dec. 13-15, 2023. This work has been submitted to the IEEE for possible publication</p></details> |
| **[Control Modes of Teleoperated Surgical Robotic System's Tools in Ophthalmic Surgery](http://arxiv.org/abs/2507.13654v2)** | 2025-10-29 | 10 pages, 11 figures |
| **[RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](http://arxiv.org/abs/2506.06677v2)** | 2025-10-29 | <details><summary>25 pa...</summary><p>25 pages, 18 figures, Accepted by NeurIPS 2025</p></details> |
| **[NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](http://arxiv.org/abs/2510.25122v1)** | 2025-10-29 |  |
| **[Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](http://arxiv.org/abs/2510.25086v1)** | 2025-10-29 |  |
| **[Scalable predictive processing framework for multitask caregiving robots](http://arxiv.org/abs/2510.25053v1)** | 2025-10-29 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PairUni: Pairwise Training for Unified Multimodal Language Models](http://arxiv.org/abs/2510.25682v1)** | 2025-10-29 |  |
| **[ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents](http://arxiv.org/abs/2510.25668v1)** | 2025-10-29 |  |
| **[Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](http://arxiv.org/abs/2510.25616v1)** | 2025-10-29 | 13 pages, 6 figures |
| **[Using VLM Reasoning to Constrain Task and Motion Planning](http://arxiv.org/abs/2510.25548v1)** | 2025-10-29 | <details><summary>8 pag...</summary><p>8 pages, 7 figures, 1 table. Submitted to ICRA 2026</p></details> |
| **[Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media](http://arxiv.org/abs/2510.25413v1)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted by RANLP 2025</p></details> |
| **[Think Twice Before You Judge: Mixture of Dual Reasoning Experts for Multimodal Sarcasm Detection](http://arxiv.org/abs/2507.04458v2)** | 2025-10-29 |  |
| **[SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](http://arxiv.org/abs/2510.25191v1)** | 2025-10-29 |  |
| **[Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models](http://arxiv.org/abs/2510.25179v1)** | 2025-10-29 |  |
| **[Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving](http://arxiv.org/abs/2503.06497v3)** | 2025-10-29 |  |
| **[RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](http://arxiv.org/abs/2506.06677v2)** | 2025-10-29 | <details><summary>25 pa...</summary><p>25 pages, 18 figures, Accepted by NeurIPS 2025</p></details> |
| **[Learning Spatial-Aware Manipulation Ordering](http://arxiv.org/abs/2510.25138v1)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](http://arxiv.org/abs/2510.25122v1)** | 2025-10-29 |  |
| **[Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection](http://arxiv.org/abs/2510.25094v1)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models](http://arxiv.org/abs/2505.16854v3)** | 2025-10-29 | <details><summary>camer...</summary><p>camera ready revision</p></details> |
| **[DRIP: Dynamic patch Reduction via Interpretable Pooling](http://arxiv.org/abs/2510.25067v1)** | 2025-10-29 |  |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Off-policy Reinforcement Learning with Model-based Exploration Augmentation](http://arxiv.org/abs/2510.25529v1)** | 2025-10-29 |  |
| **[FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving](http://arxiv.org/abs/2505.17685v2)** | 2025-10-29 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025 as Spotlight Presentation. Code: https://github.com/MIV-XJTU/FSDrive</p></details> |
| **[Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models](http://arxiv.org/abs/2510.16729v2)** | 2025-10-29 |  |
| **[AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians](http://arxiv.org/abs/2510.25129v1)** | 2025-10-29 | <details><summary>18 pa...</summary><p>18 pages, 11 figures. NeurIPS 2025; Project page: https://zju3dv.github.io/AtlasGS/</p></details> |
| **[Evolving Diagnostic Agents in a Virtual Clinical Environment](http://arxiv.org/abs/2510.24654v1)** | 2025-10-28 |  |
| **[Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks](http://arxiv.org/abs/2510.24546v1)** | 2025-10-28 |  |
| **[Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning](http://arxiv.org/abs/2502.21142v2)** | 2025-10-28 | Under review |
| **[Affordance Representation and Recognition for Autonomous Agents](http://arxiv.org/abs/2510.24459v1)** | 2025-10-28 |  |
| **[LongCat-Video Technical Report](http://arxiv.org/abs/2510.22200v2)** | 2025-10-28 |  |
| **[Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond](http://arxiv.org/abs/2405.03520v2)** | 2025-10-28 | <details><summary>This ...</summary><p>This survey will be regularly updated at: https://github.com/GigaAI-research/General-World-Models-Survey</p></details> |
| **[Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts](http://arxiv.org/abs/2510.24030v1)** | 2025-10-28 |  |
| **[COMPASS: Cross-embodiment Mobility Policy via Residual RL and Skill Synthesis](http://arxiv.org/abs/2502.16372v3)** | 2025-10-27 |  |
| **[Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](http://arxiv.org/abs/2510.23509v1)** | 2025-10-27 |  |
| **[World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](http://arxiv.org/abs/2509.24948v2)** | 2025-10-27 |  |
| **[Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](http://arxiv.org/abs/2510.23258v1)** | 2025-10-27 | Preprint version |

