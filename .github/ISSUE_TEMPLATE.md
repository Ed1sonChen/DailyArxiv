---
title: Latest 15 Papers - October 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](http://arxiv.org/abs/2510.14952v2)** | 2025-10-17 |  |
| **[VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](http://arxiv.org/abs/2510.15446v1)** | 2025-10-17 | 1st version |
| **[VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation](http://arxiv.org/abs/2510.09607v2)** | 2025-10-17 | <details><summary>Homep...</summary><p>Homepage: https://ltbai.github.io/VITA-VLA/</p></details> |
| **[Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](http://arxiv.org/abs/2510.12276v2)** | 2025-10-17 |  |
| **[RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](http://arxiv.org/abs/2510.14968v1)** | 2025-10-16 | <details><summary>39th ...</summary><p>39th Conference on Neural Information Processing Systems (NeurIPS 2025); Project Website: rdd-neurips.github.io</p></details> |
| **[VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](http://arxiv.org/abs/2510.14902v1)** | 2025-10-16 |  |
| **[QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models](http://arxiv.org/abs/2510.14836v1)** | 2025-10-16 |  |
| **[Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](http://arxiv.org/abs/2510.14300v1)** | 2025-10-16 |  |
| **[InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy](http://arxiv.org/abs/2510.13778v1)** | 2025-10-15 | Technical report |
| **[LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models](http://arxiv.org/abs/2510.13626v1)** | 2025-10-15 |  |
| **[DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](http://arxiv.org/abs/2510.13375v1)** | 2025-10-15 |  |
| **[EO-1: Interleaved Vision-Text-Action Pretraining for General Robot Control](http://arxiv.org/abs/2508.21112v4)** | 2025-10-15 |  |
| **[On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations](http://arxiv.org/abs/2510.00037v2)** | 2025-10-15 |  |
| **[USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots](http://arxiv.org/abs/2510.07869v3)** | 2025-10-15 | <details><summary>Proje...</summary><p>Project Page: https://vincentgu2000.github.io/u0project/</p></details> |
| **[Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](http://arxiv.org/abs/2510.13237v1)** | 2025-10-15 |  |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Onboard Mission Replanning for Adaptive Cooperative Multi-Robot Systems](http://arxiv.org/abs/2506.06094v2)** | 2025-10-17 | <details><summary>9 pag...</summary><p>9 pages, 5 figures, 1 table</p></details> |
| **[DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](http://arxiv.org/abs/2510.15786v1)** | 2025-10-17 |  |
| **[Development and Adaptation of Robotic Vision in the Real-World: the Challenge of Door Detection](http://arxiv.org/abs/2401.17996v2)** | 2025-10-17 |  |
| **[Contact-Aware Safety in Soft Robots Using High-Order Control Barrier and Lyapunov Functions](http://arxiv.org/abs/2505.03841v3)** | 2025-10-17 | 8 pages |
| **[Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](http://arxiv.org/abs/2510.15686v1)** | 2025-10-17 |  |
| **[HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](http://arxiv.org/abs/2510.15679v1)** | 2025-10-17 |  |
| **[Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](http://arxiv.org/abs/2509.24907v2)** | 2025-10-17 |  |
| **[VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](http://arxiv.org/abs/2510.15530v1)** | 2025-10-17 |  |
| **[U-ARM : Ultra low-cost general teleoperation interface for robot manipulation](http://arxiv.org/abs/2509.02437v3)** | 2025-10-17 |  |
| **[Exploring Conditions for Diffusion models in Robotic Control](http://arxiv.org/abs/2510.15510v1)** | 2025-10-17 | <details><summary>Proje...</summary><p>Project page: https://orca-rc.github.io/</p></details> |
| **[Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation](http://arxiv.org/abs/2508.05635v2)** | 2025-10-17 | <details><summary>https...</summary><p>https://genie-envisioner.github.io/</p></details> |
| **[General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting](http://arxiv.org/abs/2506.17462v2)** | 2025-10-17 |  |
| **[LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](http://arxiv.org/abs/2510.15220v1)** | 2025-10-17 | 8 Pages, 9 Figures |
| **[RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](http://arxiv.org/abs/2510.15189v1)** | 2025-10-16 |  |
| **[Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](http://arxiv.org/abs/2510.15114v1)** | 2025-10-16 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models](http://arxiv.org/abs/2510.15866v1)** | 2025-10-17 | <details><summary>10 Pa...</summary><p>10 Pages + 15 Supplementary Material Pages, 5 figures</p></details> |
| **[Neuro-Symbolic Spatial Reasoning in Segmentation](http://arxiv.org/abs/2510.15841v1)** | 2025-10-17 |  |
| **[PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model](http://arxiv.org/abs/2510.14528v2)** | 2025-10-17 | <details><summary>Githu...</summary><p>Github Repo: https://github.com/PaddlePaddle/PaddleOCR</p></details> |
| **[CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints](http://arxiv.org/abs/2507.19983v2)** | 2025-10-17 |  |
| **[DocMMIR: A Framework for Document Multi-modal Information Retrieval](http://arxiv.org/abs/2505.19312v3)** | 2025-10-17 | <details><summary>Accep...</summary><p>Accepted for publication at EMNLP 2025 Findings. Code and data publicly available at https://github.com/J1mL1/DocMMIR</p></details> |
| **[Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models](http://arxiv.org/abs/2509.13031v2)** | 2025-10-17 |  |
| **[FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model](http://arxiv.org/abs/2510.10921v2)** | 2025-10-17 |  |
| **[Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](http://arxiv.org/abs/2510.15430v1)** | 2025-10-17 |  |
| **[HumorDB: Can AI understand graphical humor?](http://arxiv.org/abs/2406.13564v3)** | 2025-10-17 | <details><summary>10 ma...</summary><p>10 main figures, 4 additional appendix figures</p></details> |
| **[Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](http://arxiv.org/abs/2510.15418v1)** | 2025-10-17 |  |
| **[PrefixKV: Adaptive Prefix KV Cache is What Vision Instruction-Following Models Need for Efficient Generation](http://arxiv.org/abs/2412.03409v4)** | 2025-10-17 | <details><summary>NeurI...</summary><p>NeurIPS 2025 Camera-ready Version</p></details> |
| **[Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](http://arxiv.org/abs/2510.15349v1)** | 2025-10-17 | <details><summary>22 pa...</summary><p>22 pages, 14 figures,</p></details> |
| **[VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation](http://arxiv.org/abs/2510.09607v2)** | 2025-10-17 | <details><summary>Homep...</summary><p>Homepage: https://ltbai.github.io/VITA-VLA/</p></details> |
| **[Scope: Selective Cross-modal Orchestration of Visual Perception Experts](http://arxiv.org/abs/2510.12974v2)** | 2025-10-17 | 14 pages, 2 figures |
| **[FLEX: A Largescale Multimodal, Multiview Dataset for Learning Structured Representations for Fitness Action Quality Assessment](http://arxiv.org/abs/2506.03198v3)** | 2025-10-17 | <details><summary>Datas...</summary><p>Dataset and code are available at https://github.com/HaoYin116/FLEX . Link to Project page https://haoyin116.github.io/FLEX_Dataset</p></details> |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction](http://arxiv.org/abs/2510.15422v1)** | 2025-10-17 |  |
| **[FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models](http://arxiv.org/abs/2507.23325v3)** | 2025-10-17 |  |
| **[COMPASS: Cross-embodiment Mobility Policy via Residual RL and Skill Synthesis](http://arxiv.org/abs/2502.16372v2)** | 2025-10-16 |  |
| **[Internalizing World Models via Self-Play Finetuning for Agentic RL](http://arxiv.org/abs/2510.15047v1)** | 2025-10-16 |  |
| **[Generalized Dynamics Generation towards Scannable Physical World Model](http://arxiv.org/abs/2510.15041v1)** | 2025-10-16 |  |
| **[Terra: Explorable Native 3D World Model with Point Latents](http://arxiv.org/abs/2510.14977v1)** | 2025-10-16 | <details><summary>Proje...</summary><p>Project Page: https://huang-yh.github.io/terra/</p></details> |
| **[SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](http://arxiv.org/abs/2510.14783v1)** | 2025-10-16 |  |
| **[From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models](http://arxiv.org/abs/2509.25373v4)** | 2025-10-16 |  |
| **[WoW: Towards a World omniscient World model Through Embodied Interaction](http://arxiv.org/abs/2509.22642v2)** | 2025-10-16 |  |
| **[CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving](http://arxiv.org/abs/2510.07944v2)** | 2025-10-16 |  |
| **[PoE-World: Compositional World Modeling with Products of Programmatic Experts](http://arxiv.org/abs/2505.10819v3)** | 2025-10-15 |  |
| **[PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning](http://arxiv.org/abs/2510.13809v1)** | 2025-10-15 | <details><summary>Proje...</summary><p>Project Page: https://sihuiji.github.io/PhysMaster-Page/</p></details> |
| **[Generative Universal Verifier as Multimodal Meta-Reasoner](http://arxiv.org/abs/2510.13804v1)** | 2025-10-15 |  |
| **[MTIL: Encoding Full History with Mamba for Temporal Imitation Learning](http://arxiv.org/abs/2505.12410v3)** | 2025-10-15 | <details><summary>Publi...</summary><p>Published in IEEE Robotics and Automation Letters (RA-L), 2025. 8 pages, 5 figures</p></details> |
| **[Ctrl-World: A Controllable Generative World Model for Robot Manipulation](http://arxiv.org/abs/2510.10125v2)** | 2025-10-15 | 17 pages |

