---
title: Latest 15 Papers - September 07, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](http://arxiv.org/abs/2509.04063v1)** | 2025-09-04 |  |
| **[FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](http://arxiv.org/abs/2509.04018v1)** | 2025-09-04 |  |
| **[ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes](http://arxiv.org/abs/2506.14317v3)** | 2025-09-04 | <details><summary>Accep...</summary><p>Accepted at CoRL 2025</p></details> |
| **[ANNIE: Be Careful of Your Robots](http://arxiv.org/abs/2509.03383v1)** | 2025-09-03 |  |
| **[Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](http://arxiv.org/abs/2509.02055v1)** | 2025-09-02 | <details><summary>The f...</summary><p>The first three authors contributed equally</p></details> |
| **[AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](http://arxiv.org/abs/2509.01944v1)** | 2025-09-02 |  |
| **[Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](http://arxiv.org/abs/2508.13073v2)** | 2025-09-01 | <details><summary>Proje...</summary><p>Project Page: https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation</p></details> |
| **[EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](http://arxiv.org/abs/2508.21112v2)** | 2025-09-01 |  |
| **[OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving](http://arxiv.org/abs/2509.00789v1)** | 2025-08-31 |  |
| **[A Survey on Vision-Language-Action Models for Embodied AI](http://arxiv.org/abs/2405.14093v5)** | 2025-08-31 | <details><summary>Proje...</summary><p>Project page: https://github.com/yueen-ma/Awesome-VLA</p></details> |
| **[Galaxea Open-World Dataset and G0 Dual-System VLA Model](http://arxiv.org/abs/2509.00576v1)** | 2025-08-30 | <details><summary>https...</summary><p>https://opengalaxea.github.io/G0/</p></details> |
| **[Mechanistic interpretability for steering vision-language-action models](http://arxiv.org/abs/2509.00328v1)** | 2025-08-30 | <details><summary>CoRL ...</summary><p>CoRL 2025. Project website: https://vla-mech-interp.github.io/</p></details> |
| **[CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](http://arxiv.org/abs/2508.21046v1)** | 2025-08-28 | <details><summary>23 pa...</summary><p>23 pages, 8 figures, Project Page: https://jiutian-vl.github.io/CogVLA-page</p></details> |
| **[Pixel Motion as Universal Representation for Robot Control](http://arxiv.org/abs/2505.07817v2)** | 2025-08-28 |  |
| **[Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation](http://arxiv.org/abs/2508.19958v2)** | 2025-08-28 | <details><summary>Accep...</summary><p>Accepted to CoRL 2025; Github Page: https://long-vla.github.io</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation](http://arxiv.org/abs/2509.04441v1)** | 2025-09-04 | <details><summary>proje...</summary><p>project page: https://dex-op.github.io</p></details> |
| **[Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges](http://arxiv.org/abs/2508.17449v2)** | 2025-09-04 |  |
| **[On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs](http://arxiv.org/abs/2509.04383v1)** | 2025-09-04 | 18 pages, 6 figures |
| **[Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the Roles of Information Transparency, User Control, and Proactivity](http://arxiv.org/abs/2509.04358v1)** | 2025-09-04 |  |
| **[SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars](http://arxiv.org/abs/2509.04356v1)** | 2025-09-04 |  |
| **[HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning](http://arxiv.org/abs/2508.21043v2)** | 2025-09-04 | add more references |
| **[Lightweight Kinematic and Static Modeling of Cable-Driven Continuum Robots via Actuation-Space Energy Formulation](http://arxiv.org/abs/2509.04119v1)** | 2025-09-04 | Journal |
| **[Cloud-Assisted Remote Control for Aerial Robots: From Theory to Proof-of-Concept Implementation](http://arxiv.org/abs/2509.04095v1)** | 2025-09-04 | <details><summary>6 pag...</summary><p>6 pages, 7 figures, CCGridW 2025</p></details> |
| **[Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot](http://arxiv.org/abs/2509.04076v1)** | 2025-09-04 | <details><summary>Submi...</summary><p>Submitted to ICANN 20255 Special Session on Neural Robotics</p></details> |
| **[Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning](http://arxiv.org/abs/2509.04069v1)** | 2025-09-04 |  |
| **[Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot](http://arxiv.org/abs/2509.04016v1)** | 2025-09-04 | <details><summary>ACCEP...</summary><p>ACCEPTED FOR IEEE EUROPEAN CONFERENCE ON MOBILE ROBOTS 2025. PREPRINT VERSION. ACCEPTED JUNE, 2025 AND PRESENTED SEPTEMBER, 2025</p></details> |
| **[Gathering of asynchronous robots on circle with limited visibility using finite communication](http://arxiv.org/abs/2509.04004v1)** | 2025-09-04 |  |
| **[A Digital Twin for Robotic Post Mortem Tissue Sampling using Virtual Reality](http://arxiv.org/abs/2509.02760v2)** | 2025-09-04 |  |
| **[INGRID: Intelligent Generative Robotic Design Using Large Language Models](http://arxiv.org/abs/2509.03842v1)** | 2025-09-04 | 15 pages, 6 figures |
| **[Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet](http://arxiv.org/abs/2509.03690v1)** | 2025-09-03 | <details><summary>9 pag...</summary><p>9 pages, 8 figures, 4 tables. Submitted as preprint</p></details> |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection](http://arxiv.org/abs/2509.04448v1)** | 2025-09-04 | <details><summary>EMNLP...</summary><p>EMNLP 2025; Project Homepage: https://yanzehong.github.io/trust-vl/</p></details> |
| **[GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization](http://arxiv.org/abs/2509.04334v1)** | 2025-09-04 |  |
| **[Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding](http://arxiv.org/abs/2509.04243v1)** | 2025-09-04 |  |
| **[An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](http://arxiv.org/abs/2509.04214v1)** | 2025-09-04 |  |
| **[Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations](http://arxiv.org/abs/2509.04162v1)** | 2025-09-04 |  |
| **[MUNBa: Machine Unlearning via Nash Bargaining](http://arxiv.org/abs/2411.15537v4)** | 2025-09-04 |  |
| **[DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool Interleaved Vision-Language Model](http://arxiv.org/abs/2508.13238v2)** | 2025-09-04 |  |
| **[Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection](http://arxiv.org/abs/2509.03961v1)** | 2025-09-04 |  |
| **[Defending LVLMs Against Vision Attacks through Partial-Perception Supervision](http://arxiv.org/abs/2412.12722v2)** | 2025-09-04 | <details><summary>Accep...</summary><p>Accepted to ICML 2025</p></details> |
| **[Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model](http://arxiv.org/abs/2509.03895v1)** | 2025-09-04 | <details><summary>ICCV ...</summary><p>ICCV 2025 - LIMIT Workshop</p></details> |
| **[Weakly-Supervised Learning of Dense Functional Correspondences](http://arxiv.org/abs/2509.03893v1)** | 2025-09-04 | <details><summary>Accep...</summary><p>Accepted at ICCV 2025. Project website: https://dense-functional-correspondence.github.io/</p></details> |
| **[Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](http://arxiv.org/abs/2509.03863v1)** | 2025-09-04 |  |
| **[Measuring How (Not Just Whether) VLMs Build Common Ground](http://arxiv.org/abs/2509.03805v1)** | 2025-09-04 |  |
| **[Causality-guided Prompt Learning for Vision-language Models via Visual Granulation](http://arxiv.org/abs/2509.03803v1)** | 2025-09-04 | ICCV 2025 Accepted |
| **[MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting](http://arxiv.org/abs/2509.03800v1)** | 2025-09-04 |  |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[World Model Implanting for Test-time Adaptation of Embodied Agents](http://arxiv.org/abs/2509.03956v1)** | 2025-09-04 |  |
| **[OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction](http://arxiv.org/abs/2509.03887v1)** | 2025-09-04 |  |
| **[Learning an Adversarial World Model for Automated Curriculum Generation in MARL](http://arxiv.org/abs/2509.03771v1)** | 2025-09-03 |  |
| **[CausalARC: Abstract Reasoning with Causal World Models](http://arxiv.org/abs/2509.03636v1)** | 2025-09-03 |  |
| **[Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games](http://arxiv.org/abs/2509.03479v1)** | 2025-09-03 | 6 papges |
| **[Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](http://arxiv.org/abs/2509.03345v1)** | 2025-09-03 |  |
| **[Rethinking Data Protection in the (Generative) Artificial Intelligence Era](http://arxiv.org/abs/2507.03034v4)** | 2025-09-03 | <details><summary>Persp...</summary><p>Perspective paper for a broader scientific audience. The first two authors contributed equally to this paper. 13 pages</p></details> |
| **[A Survey: Learning Embodied Intelligence from Physical Simulators and World Models](http://arxiv.org/abs/2507.00917v3)** | 2025-09-03 | <details><summary>Updat...</summary><p>Update with recent progresses. 49pages, 25figures, 6tables, github repository avalible in https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey</p></details> |
| **[Planning with Reasoning using Vision Language World Model](http://arxiv.org/abs/2509.02722v1)** | 2025-09-02 |  |
| **[Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation](http://arxiv.org/abs/2503.20425v3)** | 2025-09-02 | <details><summary>Accep...</summary><p>Accepted as a regular paper at the 2025 IEEE International Conference on Robot & Human Interactive Communication (RO-MAN). \c{opyright} 2025 IEEE. The final version will appear in IEEE Xplore</p></details> |
| **[Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models](http://arxiv.org/abs/2406.15836v2)** | 2025-09-02 | <details><summary>Accep...</summary><p>Accepted by Transactions on Machine Learning Research</p></details> |
| **[Toward a Unified Benchmark and Taxonomy of Stochastic Environments](http://arxiv.org/abs/2509.01793v1)** | 2025-09-01 |  |
| **[General agents contain world models](http://arxiv.org/abs/2506.01622v4)** | 2025-09-01 | <details><summary>Accep...</summary><p>Accepted ICML 2025. Typos corrected</p></details> |
| **[Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](http://arxiv.org/abs/2508.13073v2)** | 2025-09-01 | <details><summary>Proje...</summary><p>Project Page: https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation</p></details> |
| **[STAGE: A Stream-Centric Generative World Model for Long-Horizon Driving-Scene Simulation](http://arxiv.org/abs/2506.13138v3)** | 2025-08-31 | <details><summary>Accep...</summary><p>Accepted for 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)</p></details> |

