---
title: Latest 15 Papers - May 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Video-R1: Reinforcing Video Reasoning in MLLMs](http://arxiv.org/abs/2503.21776v3)** | 2025-05-15 | <details><summary>Proje...</summary><p>Project page: https://github.com/tulerfeng/Video-R1</p></details> |
| **[MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills](http://arxiv.org/abs/2505.06176v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted at SIGGRAPH 2025 [ACM Transactions on Graphics]; Project website: https://monetgpt.github.io</p></details> |
| **[RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](http://arxiv.org/abs/2505.02064v2)** | 2025-05-06 | <details><summary>13 pa...</summary><p>13 pages, 4 figures, 5 tables</p></details> |
| **[MLLM-Enhanced Face Forgery Detection: A Vision-Language Fusion Solution](http://arxiv.org/abs/2505.02013v1)** | 2025-05-04 |  |
| **[Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](http://arxiv.org/abs/2504.21277v1)** | 2025-04-30 |  |
| **[Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](http://arxiv.org/abs/2505.00742v1)** | 2025-04-30 |  |
| **[Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs](http://arxiv.org/abs/2504.15280v2)** | 2025-04-27 | <details><summary>Proje...</summary><p>Project page: https://danielchyeh.github.io/All-Angles-Bench/</p></details> |
| **[ZipR1: Reinforcing Token Sparsity in MLLMs](http://arxiv.org/abs/2504.18579v1)** | 2025-04-23 | work in process |
| **[STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](http://arxiv.org/abs/2503.23765v3)** | 2025-04-21 |  |
| **[A Call for New Recipes to Enhance Spatial Reasoning in MLLMs](http://arxiv.org/abs/2504.15037v1)** | 2025-04-21 |  |
| **[CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography](http://arxiv.org/abs/2504.10090v2)** | 2025-04-17 |  |
| **[EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand Multi-Source Remote Sensing Imagery](http://arxiv.org/abs/2504.12795v1)** | 2025-04-17 |  |
| **[Look Before You Decide: Prompting Active Deduction of MLLMs for Assumptive Reasoning](http://arxiv.org/abs/2404.12966v5)** | 2025-04-17 |  |
| **[AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection](http://arxiv.org/abs/2504.11914v1)** | 2025-04-16 |  |
| **[Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation](http://arxiv.org/abs/2504.11002v1)** | 2025-04-15 |  |

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Latent Action Pretraining from Videos](http://arxiv.org/abs/2410.11758v2)** | 2025-05-15 | <details><summary>ICLR ...</summary><p>ICLR 2025 Website: https://latentactionpretraining.github.io</p></details> |
| **[UniVLA: Learning to Act Anywhere with Task-centric Latent Actions](http://arxiv.org/abs/2505.06111v2)** | 2025-05-15 | <details><summary>Accep...</summary><p>Accepted to RSS 2025. Code is available at https://github.com/OpenDriveLab/UniVLA</p></details> |
| **[Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware](http://arxiv.org/abs/2505.09601v1)** | 2025-05-14 |  |
| **[RT-cache: Efficient Robot Trajectory Retrieval System](http://arxiv.org/abs/2505.09040v1)** | 2025-05-14 | <details><summary>9 pag...</summary><p>9 pages, 5 figures. Submitted to an IEEE robotics conference</p></details> |
| **[From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation](http://arxiv.org/abs/2505.08548v1)** | 2025-05-13 | Early version |
| **[TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation](http://arxiv.org/abs/2409.12514v5)** | 2025-05-13 | add more citations |
| **[DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control](http://arxiv.org/abs/2502.05855v2)** | 2025-05-13 | <details><summary>The w...</summary><p>The webpage is at https://dex-vla.github.io/</p></details> |
| **[UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation](http://arxiv.org/abs/2501.05014v2)** | 2025-05-13 | HRI 2025 |
| **[Training Strategies for Efficient Embodied Reasoning](http://arxiv.org/abs/2505.08243v1)** | 2025-05-13 |  |
| **[Pixel Motion as Universal Representation for Robot Control](http://arxiv.org/abs/2505.07817v1)** | 2025-05-12 |  |
| **[ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning](http://arxiv.org/abs/2505.07395v1)** | 2025-05-12 |  |
| **[HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation](http://arxiv.org/abs/2502.05485v4)** | 2025-05-10 | <details><summary>updat...</summary><p>update related work and results on VQA benchmarks</p></details> |
| **[CLIP-RT: Learning Language-Conditioned Robotic Policies from Natural Language Supervision](http://arxiv.org/abs/2411.00508v4)** | 2025-05-10 | <details><summary>Accep...</summary><p>Accepted to RSS 2025. Project website: https://clip-rt.github.io</p></details> |
| **[VLATest: Testing and Evaluating Vision-Language-Action Models for Robotic Manipulation](http://arxiv.org/abs/2409.12894v2)** | 2025-05-09 | <details><summary>To ap...</summary><p>To appear in FSE '25 (Proceedings of ACM Software Engineering, Vol. 2, Issue FSE, Article FSE073), 24 pages, 7 figures</p></details> |
| **[3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks](http://arxiv.org/abs/2505.05800v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted at the 1st Workshop on 3D LLM/VLA, CVPR 2025</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation](http://arxiv.org/abs/2505.10522v1)** | 2025-05-15 |  |
| **[AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics](http://arxiv.org/abs/2505.10398v1)** | 2025-05-15 | 13 pages, 9 figures |
| **[pc-dbCBS: Kinodynamic Motion Planning of Physically-Coupled Robot Teams](http://arxiv.org/abs/2505.10355v1)** | 2025-05-15 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[Joint Robotic Aerial Base Station Deployment and Wireless Backhauling in 6G Multi-hop Networks](http://arxiv.org/abs/2405.07714v2)** | 2025-05-15 | <details><summary>This ...</summary><p>This version reflects the conference publication in 2025 IEEE Wireless Communications and Networking Conference (WCNC), with a minor modified title and text content. The conference is:"Integrated Robotic Aerial Base Stations Deployment and Backhaul Design in 6G Multihop Networks," 2025 IEEE WCNC doi: 10.1109/WCNC61545.2025.10978194</p></details> |
| **[Force-Driven Validation for Collaborative Robotics in Automated Avionics Testing](http://arxiv.org/abs/2505.10224v1)** | 2025-05-15 |  |
| **[Towards Safe Robot Foundation Models Using Inductive Biases](http://arxiv.org/abs/2505.10219v1)** | 2025-05-15 | 14 pages, 5 figures |
| **[Embodied Intelligent Industrial Robotics: Concepts and Techniques](http://arxiv.org/abs/2505.09305v2)** | 2025-05-15 | <details><summary>60 pa...</summary><p>60 pages, 11 figures. The associated project can be found at https://github.com/jackyzengl/EIIR</p></details> |
| **[LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics](http://arxiv.org/abs/2312.01797v3)** | 2025-05-15 | 7 figures, 8 pages |
| **[Training People to Reward Robots](http://arxiv.org/abs/2505.10151v1)** | 2025-05-15 | 6 pages |
| **[EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation](http://arxiv.org/abs/2505.10105v1)** | 2025-05-15 |  |
| **[FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation](http://arxiv.org/abs/2505.10075v1)** | 2025-05-15 | <details><summary>Proje...</summary><p>Project page: see https://sharinka0715.github.io/FlowDreamer/</p></details> |
| **[Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering](http://arxiv.org/abs/2505.10073v1)** | 2025-05-15 | <details><summary>5 pag...</summary><p>5 pages, 4 figures, Scheduled for presentation at an upcoming conference</p></details> |
| **[To what extent can current French mobile network support agricultural robots?](http://arxiv.org/abs/2505.10044v1)** | 2025-05-15 |  |
| **[Fast Heuristic Scheduling and Trajectory Planning for Robotic Fruit Harvesters with Multiple Cartesian Arms](http://arxiv.org/abs/2505.10028v1)** | 2025-05-15 | <details><summary>This ...</summary><p>This work will be submitted to the IEEE for possible publication</p></details> |
| **[APEX: Action Priors Enable Efficient Exploration for Skill Imitation on Articulated Robots](http://arxiv.org/abs/2505.10022v1)** | 2025-05-15 |  |

## diffusion policy
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps](http://arxiv.org/abs/2505.10482v1)** | 2025-05-15 | <details><summary>9 pag...</summary><p>9 pages for main text, 23 pages in total, submitted to Neurips, 13 figures</p></details> |
| **[X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real](http://arxiv.org/abs/2505.07096v2)** | 2025-05-15 |  |
| **[VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation](http://arxiv.org/abs/2505.09577v1)** | 2025-05-14 |  |
| **[Learning Long-Context Diffusion Policies via Past-Token Prediction](http://arxiv.org/abs/2505.09561v1)** | 2025-05-14 | <details><summary>Video...</summary><p>Videos are available at https://long-context-dp.github.io</p></details> |
| **[Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU](http://arxiv.org/abs/2505.09430v1)** | 2025-05-14 |  |
| **[Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion](http://arxiv.org/abs/2505.09424v1)** | 2025-05-14 |  |
| **[Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation](http://arxiv.org/abs/2505.09144v1)** | 2025-05-14 |  |
| **[ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation](http://arxiv.org/abs/2505.08986v1)** | 2025-05-13 | <details><summary>Submi...</summary><p>Submitted for journal review</p></details> |
| **[SPOT: SE(3) Pose Trajectory Diffusion for Object-Centric Manipulation](http://arxiv.org/abs/2411.00965v2)** | 2025-05-13 |  |
| **[NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance](http://arxiv.org/abs/2505.08712v1)** | 2025-05-13 | 14 pages, 6 figures |
| **[Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness](http://arxiv.org/abs/2505.08627v1)** | 2025-05-13 |  |
| **[TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation](http://arxiv.org/abs/2409.12514v5)** | 2025-05-13 | add more citations |
| **[DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control](http://arxiv.org/abs/2502.05855v2)** | 2025-05-13 | <details><summary>The w...</summary><p>The webpage is at https://dex-vla.github.io/</p></details> |
| **[Adaptive Diffusion Policy Optimization for Robotic Manipulation](http://arxiv.org/abs/2505.08376v1)** | 2025-05-13 |  |
| **[H$^{\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning](http://arxiv.org/abs/2505.07819v1)** | 2025-05-12 |  |

