---
title: Latest 15 Papers - February 17, 2026
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DM0: An Embodied-Native Vision-Language-Action Model towards Physical AI](https://arxiv.org/abs/2602.14974v1)** | 2026-02-16 | <details><summary>Autho...</summary><p>Authors are listed in alphabetical order. Code is available at https://github.com/Dexmal/dexbotic</p></details> |
| **[DriveFine: Refining-Augmented Masked Diffusion VLA for Precise and Robust Driving](https://arxiv.org/abs/2602.14577v1)** | 2026-02-16 |  |
| **[Beyond Imitation: Reinforcement Learning-Based Sim-Real Co-Training for VLA Models](https://arxiv.org/abs/2602.12628v2)** | 2026-02-16 |  |
| **[LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.10556v2)** | 2026-02-15 | <details><summary>Proje...</summary><p>Project website: https://lap-vla.github.io</p></details> |
| **[WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL](https://arxiv.org/abs/2602.13977v1)** | 2026-02-15 | 21pages, 8 figures |
| **[VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063v2)** | 2026-02-15 | <details><summary>Proje...</summary><p>Project Page: https://sites.google.com/view/vlaw-arxiv</p></details> |
| **[Semantic-Contact Fields for Category-Level Generalizable Tactile Tool Manipulation](https://arxiv.org/abs/2602.13833v1)** | 2026-02-14 |  |
| **[MOTIF: Learning Action Motifs for Few-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.13764v1)** | 2026-02-14 |  |
| **[HBVLA: Pushing 1-Bit Post-Training Quantization for Vision-Language-Action Models](https://arxiv.org/abs/2602.13710v1)** | 2026-02-14 |  |
| **[Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement](https://arxiv.org/abs/2602.03983v2)** | 2026-02-14 |  |
| **[VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model](https://arxiv.org/abs/2602.10098v2)** | 2026-02-14 |  |
| **[FlowHOI: Flow-based Semantics-Grounded Generation of Hand-Object Interactions for Dexterous Robot Manipulation](https://arxiv.org/abs/2602.13444v1)** | 2026-02-13 | <details><summary>Proje...</summary><p>Project Page: https://huajian-zeng.github.io/projects/flowhoi/</p></details> |
| **[InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456v2)** | 2026-02-13 | <details><summary>Homep...</summary><p>Homepage: https://internrobotics.github.io/internvla-a1.github.io/</p></details> |
| **[Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control](https://arxiv.org/abs/2602.13193v1)** | 2026-02-13 |  |
| **[UniManip: General-Purpose Zero-Shot Robotic Manipulation with Agentic Operational Graph](https://arxiv.org/abs/2602.13086v1)** | 2026-02-13 | <details><summary>15 pa...</summary><p>15 pages, 12 figures, 6 tables, project page: https://henryhcliu.github.io/unimanip</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Neurosim: A Fast Simulator for Neuromorphic Robot Perception](https://arxiv.org/abs/2602.15018v1)** | 2026-02-16 | 13 pages, 6 figures |
| **[BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames](https://arxiv.org/abs/2602.15010v1)** | 2026-02-16 |  |
| **[Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations](https://arxiv.org/abs/2510.18697v3)** | 2026-02-16 | Accepted to RA-L |
| **[Language Movement Primitives: Grounding Language Models in Robot Motion](https://arxiv.org/abs/2602.02839v2)** | 2026-02-16 |  |
| **[Robot-Wearable Conversation Hand-off for Navigation](https://arxiv.org/abs/2602.14831v1)** | 2026-02-16 | <details><summary>To ap...</summary><p>To appear in Proceedings of Augmented Humans International Conference (AHs 2026)</p></details> |
| **[Scalable Multi-Robot Path Planning via Quadratic Unconstrained Binary Optimization](https://arxiv.org/abs/2602.14799v1)** | 2026-02-16 | <details><summary>21 pa...</summary><p>21 pages, 9 figures, 1 table. Accompanying open-source implementation at https://github.com/JavideuS/Spooky</p></details> |
| **[Analysis of a Cuspidal 6R Robot](https://arxiv.org/abs/2602.14794v1)** | 2026-02-16 |  |
| **[ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions](https://arxiv.org/abs/2602.14726v1)** | 2026-02-16 | <details><summary>8 pag...</summary><p>8 pages, 5, figures, Accepted for 2026 IEEE International Conference on Robotics & Automation (ICRA)</p></details> |
| **[Real-time Monocular 2D and 3D Perception of Endoluminal Scenes for Controlling Flexible Robotic Endoscopic Instruments](https://arxiv.org/abs/2602.14666v1)** | 2026-02-16 |  |
| **[Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios](https://arxiv.org/abs/2406.04955v2)** | 2026-02-16 | <details><summary>Publi...</summary><p>Published at 2024 IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</p></details> |
| **[Simulation-based Learning of Electrical Cabinet Assembly Using Robot Skills](https://arxiv.org/abs/2602.14561v1)** | 2026-02-16 | 20 pages, 14 Figures |
| **[Replanning Human-Robot Collaborative Tasks with Vision-Language Models via Semantic and Physical Dual-Correction](https://arxiv.org/abs/2602.14551v1)** | 2026-02-16 | 16 pages, 8 figures |
| **[Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots' Performance in U-Shaped Stair Climbing](https://arxiv.org/abs/2602.14473v1)** | 2026-02-16 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, International Conference on Computing in Civil Engineering (i3CE 2026)</p></details> |
| **[RoboSolver: A Multi-Agent Large Language Model Framework for Solving Robotic Arm Problems](https://arxiv.org/abs/2602.14438v1)** | 2026-02-16 |  |
| **[A Soft Wrist with Anisotropic and Selectable Stiffness for Robust Robot Learning in Contact-rich Manipulation](https://arxiv.org/abs/2602.14434v1)** | 2026-02-16 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames](https://arxiv.org/abs/2602.15010v1)** | 2026-02-16 |  |
| **[ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery](https://arxiv.org/abs/2602.14989v1)** | 2026-02-16 | <details><summary>8 Pag...</summary><p>8 Pages with 2 figures of main content. 2 pages of References. 10 pages of appendix with 6 figures</p></details> |
| **[DM0: An Embodied-Native Vision-Language-Action Model towards Physical AI](https://arxiv.org/abs/2602.14974v1)** | 2026-02-16 | <details><summary>Autho...</summary><p>Authors are listed in alphabetical order. Code is available at https://github.com/Dexmal/dexbotic</p></details> |
| **[Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis](https://arxiv.org/abs/2506.11526v4)** | 2026-02-16 | <details><summary>IEEE ...</summary><p>IEEE Open Journal of Intelligent Transportation Systems</p></details> |
| **[Efficient Test-Time Scaling for Small Vision-Language Models](https://arxiv.org/abs/2510.03574v2)** | 2026-02-16 | <details><summary>Accep...</summary><p>Accepted at ICLR 2026. Project Page: https://monurcan.github.io/efficient_test_time_scaling</p></details> |
| **[Are foundation models for computer vision good conformal predictors?](https://arxiv.org/abs/2412.06082v3)** | 2026-02-16 |  |
| **[MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs](https://arxiv.org/abs/2602.14589v1)** | 2026-02-16 |  |
| **[Top-Down Semantic Refinement for Image Captioning](https://arxiv.org/abs/2510.22391v2)** | 2026-02-16 |  |
| **[Replanning Human-Robot Collaborative Tasks with Vision-Language Models via Semantic and Physical Dual-Correction](https://arxiv.org/abs/2602.14551v1)** | 2026-02-16 | 16 pages, 8 figures |
| **[Error Patterns in Historical OCR: A Comparative Analysis of TrOCR and a Vision-Language Model](https://arxiv.org/abs/2602.14524v1)** | 2026-02-16 |  |
| **[S2D: Selective Spectral Decay for Quantization-Friendly Conditioning of Neural Activations](https://arxiv.org/abs/2602.14432v1)** | 2026-02-16 |  |
| **[Multi-Turn Adaptive Prompting Attack on Large Vision-Language Models](https://arxiv.org/abs/2602.14399v1)** | 2026-02-16 |  |
| **[LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge](https://arxiv.org/abs/2602.07849v2)** | 2026-02-16 | <details><summary>15 pa...</summary><p>15 pages, 9 figures ,9 tables, preprint</p></details> |
| **[LVLM-COUNT: Enhancing the Counting Ability of Large Vision-Language Models](https://arxiv.org/abs/2412.00686v4)** | 2026-02-16 | <details><summary>38 pa...</summary><p>38 pages, 24 Figures, 19 Tables</p></details> |
| **[Moving Beyond Sparse Grounding with Complete Screen Parsing Supervision](https://arxiv.org/abs/2602.14276v1)** | 2026-02-15 | 28 pages, 15 figures |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Simulating the Real World: A Unified Survey of Multimodal Generative Models](https://arxiv.org/abs/2503.04641v3)** | 2026-02-16 | <details><summary>Repos...</summary><p>Repository for the related papers at https://github.com/ALEEEHU/World-Simulator</p></details> |
| **[Cold-Start Personalization via Training-Free Priors from Structured World Models](https://arxiv.org/abs/2602.15012v1)** | 2026-02-16 | <details><summary>24 pa...</summary><p>24 pages, 4 figures, 4 tables</p></details> |
| **[Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis](https://arxiv.org/abs/2506.11526v4)** | 2026-02-16 | <details><summary>IEEE ...</summary><p>IEEE Open Journal of Intelligent Transportation Systems</p></details> |
| **[World Models for Policy Refinement in StarCraft II](https://arxiv.org/abs/2602.14857v1)** | 2026-02-16 |  |
| **[WebWorld: A Large-Scale World Model for Web Agent Training](https://arxiv.org/abs/2602.14721v1)** | 2026-02-16 |  |
| **[WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control](https://arxiv.org/abs/2602.14351v1)** | 2026-02-15 | <details><summary>Accep...</summary><p>Accepted at ICLR 2026. OpenReview: https://openreview.net/forum?id=mzLOnTb3WH</p></details> |
| **[Self-Improving World Modelling with Latent Actions](https://arxiv.org/abs/2602.06130v2)** | 2026-02-15 |  |
| **[ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving](https://arxiv.org/abs/2511.11079v3)** | 2026-02-15 | <details><summary>KDD 2...</summary><p>KDD 2026 (Datasets and Benchmarks) accepted</p></details> |
| **[WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL](https://arxiv.org/abs/2602.13977v1)** | 2026-02-15 | 21pages, 8 figures |
| **[VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063v2)** | 2026-02-15 | <details><summary>Proje...</summary><p>Project Page: https://sites.google.com/view/vlaw-arxiv</p></details> |
| **[Debugging code world models](https://arxiv.org/abs/2602.07672v2)** | 2026-02-14 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, under review in conference</p></details> |
| **[Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing](https://arxiv.org/abs/2602.13628v1)** | 2026-02-14 | 16 pages, 10 figures |
| **[VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model](https://arxiv.org/abs/2602.10098v2)** | 2026-02-14 |  |
| **[From Snapshot Sensing to Persistent EM World Modeling: A Generative-Space Perspective for ISAC](https://arxiv.org/abs/2602.13554v1)** | 2026-02-14 | <details><summary>7 pag...</summary><p>7 pages, 6 figures/tables</p></details> |
| **[InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456v2)** | 2026-02-13 | <details><summary>Homep...</summary><p>Homepage: https://internrobotics.github.io/internvla-a1.github.io/</p></details> |

