---
title: Latest 15 Papers - May 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents](http://arxiv.org/abs/2505.14418v1)** | 2025-05-20 | <details><summary>25 pa...</summary><p>25 pages, 10 figures, 12 Tables</p></details> |
| **[ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations](http://arxiv.org/abs/2505.14404v1)** | 2025-05-20 |  |
| **[TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs](http://arxiv.org/abs/2505.11275v3)** | 2025-05-20 | Preprint |
| **[VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](http://arxiv.org/abs/2505.10917v2)** | 2025-05-19 |  |
| **[Can MLLMs Generalize to Multi-Party dialog? Exploring Multilingual Response Generation in Complex Scenarios](http://arxiv.org/abs/2501.11269v2)** | 2025-05-19 |  |
| **[BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](http://arxiv.org/abs/2505.12620v1)** | 2025-05-19 |  |
| **[VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning](http://arxiv.org/abs/2505.12434v1)** | 2025-05-18 | <details><summary>Code:...</summary><p>Code: https://github.com/QiWang98/VideoRFT</p></details> |
| **[Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning](http://arxiv.org/abs/2505.12432v1)** | 2025-05-18 |  |
| **[MLLM-based Discovery of Intrinsic Coordinates and Governing Equations from High-Dimensional Data](http://arxiv.org/abs/2505.11940v1)** | 2025-05-17 |  |
| **[ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing](http://arxiv.org/abs/2505.11935v1)** | 2025-05-17 | <details><summary>Accep...</summary><p>Accept by ACL2025 Findings, preprint version</p></details> |
| **[Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](http://arxiv.org/abs/2505.11141v1)** | 2025-05-16 |  |
| **[Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](http://arxiv.org/abs/2505.10862v1)** | 2025-05-16 | <details><summary>6 pag...</summary><p>6 pages, 5 figures, 2 tables</p></details> |
| **[Video-R1: Reinforcing Video Reasoning in MLLMs](http://arxiv.org/abs/2503.21776v3)** | 2025-05-15 | <details><summary>Proje...</summary><p>Project page: https://github.com/tulerfeng/Video-R1</p></details> |
| **[MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills](http://arxiv.org/abs/2505.06176v1)** | 2025-05-09 | <details><summary>Accep...</summary><p>Accepted at SIGGRAPH 2025 [ACM Transactions on Graphics]; Project website: https://monetgpt.github.io</p></details> |
| **[RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](http://arxiv.org/abs/2505.02064v2)** | 2025-05-06 | <details><summary>13 pa...</summary><p>13 pages, 4 figures, 5 tables</p></details> |

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models](http://arxiv.org/abs/2409.15250v3)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted at ICRA-2025, Atlanta</p></details> |
| **[AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory](http://arxiv.org/abs/2505.14030v1)** | 2025-05-20 |  |
| **[RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction](http://arxiv.org/abs/2505.12224v2)** | 2025-05-20 |  |
| **[InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning](http://arxiv.org/abs/2505.13888v1)** | 2025-05-20 |  |
| **[Training Strategies for Efficient Embodied Reasoning](http://arxiv.org/abs/2505.08243v2)** | 2025-05-17 | <details><summary>Updat...</summary><p>Updated figure layout, added project page link</p></details> |
| **[OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning](http://arxiv.org/abs/2505.11917v1)** | 2025-05-17 |  |
| **[Task Reconstruction and Extrapolation for $Ï€_0$ using Text Latent](http://arxiv.org/abs/2505.03500v2)** | 2025-05-16 |  |
| **[Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions](http://arxiv.org/abs/2505.11214v1)** | 2025-05-16 |  |
| **[Conditioning Matters: Training Diffusion Policies is Faster Than You Think](http://arxiv.org/abs/2505.11123v1)** | 2025-05-16 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2505.10105</p></details> |
| **[Latent Action Pretraining from Videos](http://arxiv.org/abs/2410.11758v2)** | 2025-05-15 | <details><summary>ICLR ...</summary><p>ICLR 2025 Website: https://latentactionpretraining.github.io</p></details> |
| **[UniVLA: Learning to Act Anywhere with Task-centric Latent Actions](http://arxiv.org/abs/2505.06111v2)** | 2025-05-15 | <details><summary>Accep...</summary><p>Accepted to RSS 2025. Code is available at https://github.com/OpenDriveLab/UniVLA</p></details> |
| **[Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware](http://arxiv.org/abs/2505.09601v1)** | 2025-05-14 |  |
| **[RT-cache: Efficient Robot Trajectory Retrieval System](http://arxiv.org/abs/2505.09040v1)** | 2025-05-14 | <details><summary>9 pag...</summary><p>9 pages, 5 figures. Submitted to an IEEE robotics conference</p></details> |
| **[From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation](http://arxiv.org/abs/2505.08548v1)** | 2025-05-13 | Early version |
| **[TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation](http://arxiv.org/abs/2409.12514v5)** | 2025-05-13 | add more citations |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models](http://arxiv.org/abs/2409.15250v3)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted at ICRA-2025, Atlanta</p></details> |
| **[NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation](http://arxiv.org/abs/2505.14526v1)** | 2025-05-20 | <details><summary>Submi...</summary><p>Submitted for publication. Under review (2025)</p></details> |
| **[End-to-End and Highly-Efficient Differentiable Simulation for Robotics](http://arxiv.org/abs/2409.07107v2)** | 2025-05-20 |  |
| **[Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds](http://arxiv.org/abs/2505.14366v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late Breaking Report</p></details> |
| **[Sampling-Based System Identification with Active Exploration for Legged Robot Sim2Real Learning](http://arxiv.org/abs/2505.14266v1)** | 2025-05-20 |  |
| **[Safe Distributed Control of Multi-Robot Systems with Communication Delays](http://arxiv.org/abs/2402.09382v4)** | 2025-05-20 | <details><summary>Copyr...</summary><p>Copyright (c) 2025 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org</p></details> |
| **[GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets](http://arxiv.org/abs/2505.10973v2)** | 2025-05-20 | <details><summary>18pag...</summary><p>18pages, 16figures, 6tables</p></details> |
| **[Task-oriented Robotic Manipulation with Vision Language Models](http://arxiv.org/abs/2410.15863v2)** | 2025-05-20 |  |
| **[AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory](http://arxiv.org/abs/2505.14030v1)** | 2025-05-20 |  |
| **[RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction](http://arxiv.org/abs/2505.12224v2)** | 2025-05-20 |  |
| **[Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning](http://arxiv.org/abs/2505.13925v1)** | 2025-05-20 |  |
| **[Robotic Monitoring of Colorimetric Leaf Sensors for Precision Agriculture](http://arxiv.org/abs/2505.13916v1)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to the Novel Approaches for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025</p></details> |
| **[Enhancing Robot Navigation Policies with Task-Specific Uncertainty Managements](http://arxiv.org/abs/2505.13837v1)** | 2025-05-20 |  |
| **[Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams](http://arxiv.org/abs/2505.13834v1)** | 2025-05-20 | 11 pages, 12 figures |
| **[RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations](http://arxiv.org/abs/2411.16959v2)** | 2025-05-20 | <details><summary>Accep...</summary><p>Accepted to 2025 IEEE International Conference on Robotics and Automation (ICRA)</p></details> |

## diffusion policy
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Practical Guide for Incorporating Symmetry in Diffusion Policy](http://arxiv.org/abs/2505.13431v2)** | 2025-05-20 |  |
| **[Learning to Group and Grasp Multiple Objects](http://arxiv.org/abs/2502.08452v2)** | 2025-05-20 |  |
| **[Learning Long-Context Diffusion Policies via Past-Token Prediction](http://arxiv.org/abs/2505.09561v2)** | 2025-05-19 | <details><summary>Video...</summary><p>Videos are available at https://long-context-dp.github.io</p></details> |
| **[MTIL: Encoding Full History with Mamba for Temporal Imitation Learning](http://arxiv.org/abs/2505.12410v1)** | 2025-05-18 | <details><summary>16 pa...</summary><p>16 pages,6 figures,Submitted to IEEE RAL</p></details> |
| **[Zero-Shot Visual Generalization in Robot Manipulation](http://arxiv.org/abs/2505.11719v1)** | 2025-05-16 |  |
| **[Fast and Robust Visuomotor Riemannian Flow Matching Policy](http://arxiv.org/abs/2412.10855v2)** | 2025-05-16 | <details><summary>17 pa...</summary><p>17 pages, 12 figures, 12 tables, project website: https://sites.google.com/view/rfmp</p></details> |
| **[Exploratory Diffusion Model for Unsupervised Reinforcement Learning](http://arxiv.org/abs/2502.07279v2)** | 2025-05-16 |  |
| **[Conditioning Matters: Training Diffusion Policies is Faster Than You Think](http://arxiv.org/abs/2505.11123v1)** | 2025-05-16 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2505.10105</p></details> |
| **[Prior-Guided Diffusion Planning for Offline Reinforcement Learning](http://arxiv.org/abs/2505.10881v1)** | 2025-05-16 |  |
| **[NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance](http://arxiv.org/abs/2505.08712v2)** | 2025-05-15 | <details><summary>Proje...</summary><p>Project Page: https://wzcai99.github.io/navigation-diffusion-policy.github.io/</p></details> |
| **[Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps](http://arxiv.org/abs/2505.10482v1)** | 2025-05-15 | <details><summary>9 pag...</summary><p>9 pages for main text, 23 pages in total, submitted to Neurips, 13 figures</p></details> |
| **[X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real](http://arxiv.org/abs/2505.07096v2)** | 2025-05-15 |  |
| **[VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation](http://arxiv.org/abs/2505.09577v1)** | 2025-05-14 |  |
| **[Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU](http://arxiv.org/abs/2505.09430v1)** | 2025-05-14 |  |
| **[Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion](http://arxiv.org/abs/2505.09424v1)** | 2025-05-14 |  |

