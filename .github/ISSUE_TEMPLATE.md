---
title: Latest 15 Papers - September 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Ed1sonChen/DailyArxiv) page for a better reading experience and more papers.**

## Vision Language Action
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](http://arxiv.org/abs/2509.14143v1)** | 2025-09-17 | <details><summary>8 pag...</summary><p>8 pages, 5 figures, 1 table</p></details> |
| **[SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model](http://arxiv.org/abs/2509.14138v1)** | 2025-09-17 | <details><summary>8 pag...</summary><p>8 pages, 9 figures, 1 table</p></details> |
| **[GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model](http://arxiv.org/abs/2509.14117v1)** | 2025-09-17 | Under Review |
| **[Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach](http://arxiv.org/abs/2509.13774v1)** | 2025-09-17 |  |
| **[AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](http://arxiv.org/abs/2509.13769v1)** | 2025-09-17 |  |
| **[TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning](http://arxiv.org/abs/2509.11839v2)** | 2025-09-17 |  |
| **[Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations](http://arxiv.org/abs/2509.11417v2)** | 2025-09-17 | <details><summary>Proje...</summary><p>Project Page: https://gen-vla.github.io/</p></details> |
| **[ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation](http://arxiv.org/abs/2505.22159v2)** | 2025-09-16 |  |
| **[FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning](http://arxiv.org/abs/2507.23318v3)** | 2025-09-16 | 9 pages, 5 figures |
| **[The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](http://arxiv.org/abs/2509.12594v1)** | 2025-09-16 | <details><summary>Under...</summary><p>Under review. Project site: https://liauto-research.github.io/LightVLA</p></details> |
| **[Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs](http://arxiv.org/abs/2509.11480v1)** | 2025-09-15 | <details><summary>To ap...</summary><p>To appear in the Asilomar Conference on Signals, Systems, and Computers 2025</p></details> |
| **[OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](http://arxiv.org/abs/2509.13347v1)** | 2025-09-13 |  |
| **[SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](http://arxiv.org/abs/2509.09674v1)** | 2025-09-11 |  |
| **[VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model](http://arxiv.org/abs/2509.09372v1)** | 2025-09-11 |  |
| **[villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](http://arxiv.org/abs/2507.23682v2)** | 2025-09-11 | <details><summary>Proje...</summary><p>Project page: https://aka.ms/villa-x</p></details> |

## robot
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](http://arxiv.org/abs/2509.14228v1)** | 2025-09-17 |  |
| **[CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping](http://arxiv.org/abs/2509.14143v1)** | 2025-09-17 | <details><summary>8 pag...</summary><p>8 pages, 5 figures, 1 table</p></details> |
| **[Cybersecurity AI: Humanoid Robots as Attack Vectors](http://arxiv.org/abs/2509.14139v1)** | 2025-09-17 |  |
| **[Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks](http://arxiv.org/abs/2509.14127v1)** | 2025-09-17 |  |
| **[The Cybersecurity of a Humanoid Robot](http://arxiv.org/abs/2509.14096v1)** | 2025-09-17 |  |
| **[Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots](http://arxiv.org/abs/2509.14075v1)** | 2025-09-17 |  |
| **[TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems](http://arxiv.org/abs/2509.14025v1)** | 2025-09-17 |  |
| **[FlowAct: A Proactive Multimodal Human-robot Interaction System with Continuous Flow of Perception and Modular Action Sub-systems](http://arxiv.org/abs/2408.15864v3)** | 2025-09-17 | <details><summary>Paper...</summary><p>Paper accepted at ICPRAM 2025</p></details> |
| **[The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot](http://arxiv.org/abs/2509.13948v1)** | 2025-09-17 | <details><summary>In pr...</summary><p>In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE RO-MAN 2025: https://ro-man2025.org/</p></details> |
| **[PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](http://arxiv.org/abs/2509.13903v1)** | 2025-09-17 | <details><summary>submi...</summary><p>submitted to IEEE conference</p></details> |
| **[Using Petri Nets for Context-Adaptive Robot Explanations](http://arxiv.org/abs/2509.13861v1)** | 2025-09-17 | <details><summary>In pr...</summary><p>In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE RO-MAN 2025: https://www.ro-man2025.org/</p></details> |
| **[ORCA: An Open-Source, Reliable, Cost-Effective, Anthropomorphic Robotic Hand for Uninterrupted Dexterous Task Learning](http://arxiv.org/abs/2504.04259v2)** | 2025-09-17 | <details><summary>This ...</summary><p>This work has been accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025</p></details> |
| **[How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots](http://arxiv.org/abs/2509.13827v1)** | 2025-09-17 | 9 pages, 6 figures |
| **[Behavior Foundation Model for Humanoid Robots](http://arxiv.org/abs/2509.13780v1)** | 2025-09-17 |  |
| **[Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](http://arxiv.org/abs/2509.13731v1)** | 2025-09-17 |  |

## Vision Language Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Cin√©aste: A Fine-grained Contextual Movie Question Answering Benchmark](http://arxiv.org/abs/2509.14227v1)** | 2025-09-17 | <details><summary>11 pa...</summary><p>11 pages, 5 figures, 5 tables</p></details> |
| **[TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](http://arxiv.org/abs/2509.14172v1)** | 2025-09-17 |  |
| **[VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](http://arxiv.org/abs/2509.14060v1)** | 2025-09-17 |  |
| **[Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems](http://arxiv.org/abs/2509.06996v2)** | 2025-09-17 |  |
| **[Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](http://arxiv.org/abs/2509.13939v1)** | 2025-09-17 |  |
| **[Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](http://arxiv.org/abs/2509.13919v1)** | 2025-09-17 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](http://arxiv.org/abs/2509.13858v1)** | 2025-09-17 |  |
| **[Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](http://arxiv.org/abs/2509.13836v1)** | 2025-09-17 | <details><summary>Accep...</summary><p>Accepted by EMNLP2025 Finding</p></details> |
| **[Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease](http://arxiv.org/abs/2509.07613v2)** | 2025-09-17 |  |
| **[Iterative Prompt Refinement for Safer Text-to-Image Generation](http://arxiv.org/abs/2509.13760v1)** | 2025-09-17 |  |
| **[Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings](http://arxiv.org/abs/2509.13731v1)** | 2025-09-17 |  |
| **[Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild](http://arxiv.org/abs/2505.11350v4)** | 2025-09-17 | <details><summary>Accep...</summary><p>Accepted for presentation at CORL 2025. Code, models, and data are available at https://search-tta.github.io/</p></details> |
| **[DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](http://arxiv.org/abs/2509.13666v1)** | 2025-09-17 | <details><summary>submi...</summary><p>submitted to ICRA 2026</p></details> |
| **[Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations](http://arxiv.org/abs/2509.11417v2)** | 2025-09-17 | <details><summary>Proje...</summary><p>Project Page: https://gen-vla.github.io/</p></details> |
| **[Singular Value Few-shot Adaptation of Vision-Language Models](http://arxiv.org/abs/2509.03740v2)** | 2025-09-16 | <details><summary>10 pa...</summary><p>10 pages, 2 figures, 8 tables</p></details> |

## world model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Brain Inspired Probabilistic Occupancy Grid Mapping with Vector Symbolic Architectures](http://arxiv.org/abs/2408.09066v4)** | 2025-09-17 |  |
| **[PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models](http://arxiv.org/abs/2509.13903v1)** | 2025-09-17 | <details><summary>submi...</summary><p>submitted to IEEE conference</p></details> |
| **[DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue](http://arxiv.org/abs/2410.09252v2)** | 2025-09-17 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 Findings</p></details> |
| **[GWM: Towards Scalable Gaussian World Models for Robotic Manipulation](http://arxiv.org/abs/2508.17600v2)** | 2025-09-17 | <details><summary>Publi...</summary><p>Published at ICCV 2025. Project page: https://gaussian-world-model.github.io/</p></details> |
| **[From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](http://arxiv.org/abs/2509.13389v1)** | 2025-09-16 | 10 pages, 3 figures |
| **[Empowering Multi-Robot Cooperation via Sequential World Models](http://arxiv.org/abs/2509.13095v1)** | 2025-09-16 |  |
| **[A tree-based Polynomial Chaos expansion for surrogate modeling and sensitivity analysis of complex numerical models](http://arxiv.org/abs/2509.13384v1)** | 2025-09-16 |  |
| **[Methodology of Algorithm Engineering](http://arxiv.org/abs/2310.18979v2)** | 2025-09-16 |  |
| **[Enhancing Physical Consistency in Lightweight World Models](http://arxiv.org/abs/2509.12437v1)** | 2025-09-15 | 8 pages |
| **[Causal-Symbolic Meta-Learning (CSML): Inducing Causal World Models for Few-Shot Generalization](http://arxiv.org/abs/2509.12387v1)** | 2025-09-15 | 10 pages, 4 figures |
| **[OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling](http://arxiv.org/abs/2509.12201v1)** | 2025-09-15 | <details><summary>https...</summary><p>https://yangzhou24.github.io/OmniWorld/</p></details> |
| **[Learning to Generate 4D LiDAR Sequences](http://arxiv.org/abs/2509.11959v1)** | 2025-09-15 | <details><summary>Abstr...</summary><p>Abstract Paper (Non-Archival) @ ICCV 2025 Wild3D Workshop; GitHub Repo at https://lidarcrafter.github.io/</p></details> |
| **[Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics](http://arxiv.org/abs/2509.11943v1)** | 2025-09-15 | <details><summary>10 pa...</summary><p>10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at NeuralIPS</p></details> |
| **[Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?](http://arxiv.org/abs/2509.10875v1)** | 2025-09-13 |  |
| **[Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models](http://arxiv.org/abs/2405.13798v4)** | 2025-09-12 |  |

